{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84671b3-627a-4537-a768-d2e886c7c0ae",
   "metadata": {},
   "source": [
    "# Ensemble Modelling\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Ensemble Methodology](#2.-Ensemble-Methodology)\n",
    "3. [Ensemble Modelling](#3.-Ensemble-Modelling)\n",
    "4. [Compute Final Evaluation Metrics](#4.-Compute-Final-Evaluation-Metrics)\n",
    "5. [Ensemble Model Evaluation](#5.-Ensemble-Model-Evaluation)\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Ensemble modelling is a machine learning technique that combines multiple individual models to improve predictive performance. By aggregating the strengths of diverse models, ensembles often achieve better accuracy and robustness than any single model alone (Meller et al., 2014). \n",
    "\n",
    "In the context of species distribution modelling (SDM), ensemble approaches integrate predictions from various statistical techniques to enhance the reliability of forecasts. This method accounts for uncertainties inherent in individual models, leading to more robust predictions (Ramirez-Reyes et al., 2021).\n",
    "\n",
    "### **Common Ensemble Methods**\n",
    "\n",
    "1. **Bagging (Bootstrap Aggregating)**: This technique involves training multiple models on different subsets of the data, created through random sampling with replacement. The final prediction is typically an average (for regression) or majority vote (for classification) of the individual models' outputs. \n",
    "\n",
    "2. **Boosting**: Boosting sequentially trains models, each focusing on correcting the errors of its predecessor. Models are weighted based on their performance, and the ensemble combines them to produce a strong predictor. \n",
    "\n",
    "3. **Stacking**: In stacking, multiple models are trained to predict the same outcome. Their predictions are then used as inputs for a higher-level model, which learns to combine them optimally.\n",
    "\n",
    "## 2. Ensemble Methodology\n",
    "\n",
    "### **2.1 Selection of Models for Ensemble**\n",
    "Based on the previous model evaluation and comparison, Random Forest (RF) and XGBoost consistently outperformed other models, demonstrating the highest AUC-ROC, precision, recall, and F1-score across all species. MaxEnt showed moderate performance, particularly in recall, but had limitations in precision, suggesting a tendency for overprediction. GLM and GAM performed the worst overall, indicating they may not fully capture the complexity of amphibian distributions.\n",
    "\n",
    "Thus, this study will prioritise RF and XGBoost as the core models in the ensemble and consider MaxEnt for added diversity while downweighting its influence. GLM and GAM may still contribute to the ensemble for additional variance but will not drive final predictions.\n",
    "\n",
    "### **2.2 Model Weighting and Aggregation Methods**\n",
    "To integrate multiple models, this study will explore different ensemble techniques:\n",
    "\n",
    "#### 1. Averaging Ensemble:\n",
    "- Compute the mean probability of presence across RF, XGBoost, and MaxEnt.\n",
    "- Weight models according to their precision and recall (e.g., RF and XGBoost given higher weight, MaxEnt downweighted).\n",
    "#### 2. Majority Voting Ensemble (for binary presence/absence predictions):\n",
    "- Classify a species as present if at least two out of three models predict presence.\n",
    "#### 3. Stacked Ensemble (if time allows):\n",
    "Train a meta-classifier (e.g., logistic regression) using predictions from individual models as inputs.\n",
    "\n",
    "### **2.3 Calibration and Performance Evaluation**\n",
    "To ensure the ensemble predictions are robust, the following evaluation metrics will be recalculated:\n",
    "\n",
    "- AUC-ROC and Precision-Recall curves\n",
    "- Sensitivity-specificity trade-offs\n",
    "- Confusion matrix analysis\n",
    "- Uncertainty quantification (standard deviation in predictions)\n",
    "\n",
    "The ensemble's performance will be compared to individual models to determine whether it achieves higher predictive accuracy and reliability.\n",
    "\n",
    "### **2.4 Spatial Mapping of Ensemble Predictions**\n",
    "Once ensemble predictions are finalised, they will be spatially visualised using GIS tools to assess habitat suitability for target amphibian species. Uncertainty maps will also be generated to highlight regions with high model disagreement.\n",
    "\n",
    "### **2.5 Methodology Rationale**\n",
    "This study aims to leverage the advantages of ensemble modelling to provide more accurate, reliable, and ecologically meaningful habitat suitability predictions. The rationale for this approach is:\n",
    "1. Tree-based models (RF and XGBoost) demonstrate strong performance and capture complex species-environment relationships.\n",
    "2. MaxEnt contributes additional ecological insightsand has been widely used in SDMs, but its predictions will be weighted lower to account for overprediction tendencies.\n",
    "3. Averaging and majority voting improve robustness, ensuring predictions are not overly reliant on any single model.\n",
    "4. Uncertainty quantification will guide conservation decision-making, particularly for identifying regions where predictions are less certain.\n",
    "\n",
    "By following this approach, the ensemble model will integrate the strengths of individual models, enhance predictive reliability, and contribute valuable insights for amphibian conservation and Blue-Green Infrastructure planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7188149-0c65-40b5-bc30-339405a97144",
   "metadata": {},
   "source": [
    "## 3. Ensemble Modelling\n",
    "### 3.1 Load Model Predictions and Prepare for Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d12974-c5b0-43cf-95cb-3bd2eb8a87ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing ensemble predictions for Bufo bufo...\n",
      "‚úÖ Merged predictions saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\\Bufo bufo_Ensemble_Predictions.csv\n",
      "üîç Processing ensemble predictions for Rana temporaria...\n",
      "‚úÖ Merged predictions saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\\Rana temporaria_Ensemble_Predictions.csv\n",
      "üîç Processing ensemble predictions for Lissotriton helveticus...\n",
      "‚úÖ Merged predictions saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\\Lissotriton helveticus_Ensemble_Predictions.csv\n",
      "\n",
      "üöÄ Ensemble prediction files ready for next steps!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define base directory\n",
    "base_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\"\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Define selected models for ensemble\n",
    "selected_models = [\"RF\", \"XGBoost\", \"MaxEnt\"]\n",
    "\n",
    "# Define paths for each model\n",
    "model_dirs = {\n",
    "    \"RF\": os.path.join(base_dir, \"RandomForest\"),\n",
    "    \"XGBoost\": os.path.join(base_dir, \"XGBoost\"),\n",
    "    \"MaxEnt\": os.path.join(base_dir, \"Maxent\")\n",
    "}\n",
    "\n",
    "# Define file patterns for each model\n",
    "file_patterns = {\n",
    "    \"RF\": os.path.join(\"{species}\", \"Test_Predictions.csv\"),\n",
    "    \"XGBoost\": os.path.join(\"{species}\", \"Aggregated_Test_Predictions.csv\"),\n",
    "    \"MaxEnt\": \"Maxent_{species}_TestPredictions.csv\"\n",
    "}\n",
    "\n",
    "# Define output directory for merged predictions\n",
    "ensemble_output_dir = os.path.join(base_dir, \"Ensemble_Predictions\")\n",
    "os.makedirs(ensemble_output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each species\n",
    "for species in species_list:\n",
    "    print(f\"üîç Processing ensemble predictions for {species}...\")\n",
    "\n",
    "    merged_df = None  # Initialize dataframe for storing merged predictions\n",
    "\n",
    "    for model in selected_models:\n",
    "        formatted_species = species.replace(\" \", \"_\")  # Adjust for file naming\n",
    "        file_path = os.path.join(model_dirs[model], file_patterns[model].format(species=formatted_species))\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"‚ö†Ô∏è Missing prediction file for {species} - {model}: {file_path}\")\n",
    "            continue  # Skip this model if the file is missing\n",
    "\n",
    "        # Load model predictions in chunks (if necessary)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, dtype={\"True_Label\": \"int8\", \"Predicted_Probability\": \"float32\"})\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading {species} - {model}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Rename columns\n",
    "        df = df.rename(columns={\"True_Label\": \"True_Label\", \"Predicted_Probability\": f\"{model}_Probability\"})\n",
    "\n",
    "        # Reduce memory usage\n",
    "        df[f\"{model}_Probability\"] = df[f\"{model}_Probability\"].astype(np.float32)\n",
    "\n",
    "        # Merge into a single dataframe\n",
    "        if merged_df is None:\n",
    "            merged_df = df.copy()\n",
    "        else:\n",
    "            merged_df = pd.concat([merged_df, df[f\"{model}_Probability\"]], axis=1)\n",
    "\n",
    "        del df  # Free up memory\n",
    "\n",
    "    # Save the merged predictions in chunks\n",
    "    if merged_df is not None and not merged_df.empty:\n",
    "        output_file = os.path.join(ensemble_output_dir, f\"{species}_Ensemble_Predictions.csv\")\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"‚úÖ Merged predictions saved: {output_file}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No valid predictions available for {species}.\")\n",
    "\n",
    "    del merged_df  # Free memory after each species\n",
    "\n",
    "print(\"\\nüöÄ Ensemble prediction files ready for next steps!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74566b61-58ef-4ac4-a20e-11d840e233c2",
   "metadata": {},
   "source": [
    "### 3.2 Weighted Ensemble Averaging\n",
    "\n",
    "**Why Use Averaging?**\n",
    "- This approach reduces individual model biases and leverages the strengths of multiple models.\n",
    "- Averaging probabilities smooths extreme values, leading to better generalisation.\n",
    "- It is less prone to overfitting compared to single models.\n",
    "\n",
    "The code below assigns weights based on **multiple performance metrics** (AUC-ROC, Precision, Recall, and F1-score), normalises them, and applies a weighted averaging scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f24e1c6d-b4a1-4756-8399-bf0a1e106b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Computing weighted ensemble predictions for Bufo bufo...\n",
      "‚úÖ Saved final ensemble model for Bufo bufo at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Bufo bufo_Final_Ensemble_Model.pkl\n",
      "üîç Computing weighted ensemble predictions for Rana temporaria...\n",
      "‚úÖ Saved final ensemble model for Rana temporaria at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Rana temporaria_Final_Ensemble_Model.pkl\n",
      "üîç Computing weighted ensemble predictions for Lissotriton helveticus...\n",
      "‚úÖ Saved final ensemble model for Lissotriton helveticus at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Lissotriton helveticus_Final_Ensemble_Model.pkl\n",
      "\n",
      "üöÄ Weighted ensemble averaging complete! Ready for threshold selection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Define input and output directories\n",
    "ensemble_input_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\"\n",
    "ensemble_output_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\"\n",
    "os.makedirs(ensemble_output_dir, exist_ok=True)\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Define performance metrics for weighting (these values should be updated with your actual model metrics)\n",
    "performance_metrics = {\n",
    "    \"Bufo bufo\": {\n",
    "        \"RF\": {\"AUC-ROC\": 0.910, \"Precision\": 0.994, \"Recall\": 0.816, \"F1\": 0.896},\n",
    "        \"XGBoost\": {\"AUC-ROC\": 0.875, \"Precision\": 0.809, \"Recall\": 0.801, \"F1\": 0.805},\n",
    "        \"MaxEnt\": {\"AUC-ROC\": 0.867, \"Precision\": 0.419, \"Recall\": 0.720, \"F1\": 0.530},\n",
    "    },\n",
    "    \"Rana temporaria\": {\n",
    "        \"RF\": {\"AUC-ROC\": 0.949, \"Precision\": 1.000, \"Recall\": 0.863, \"F1\": 0.927},\n",
    "        \"XGBoost\": {\"AUC-ROC\": 0.909, \"Precision\": 0.837, \"Recall\": 0.855, \"F1\": 0.846},\n",
    "        \"MaxEnt\": {\"AUC-ROC\": 0.869, \"Precision\": 0.363, \"Recall\": 0.656, \"F1\": 0.467},\n",
    "    },\n",
    "    \"Lissotriton helveticus\": {\n",
    "        \"RF\": {\"AUC-ROC\": 0.915, \"Precision\": 0.989, \"Recall\": 0.777, \"F1\": 0.870},\n",
    "        \"XGBoost\": {\"AUC-ROC\": 0.834, \"Precision\": 0.803, \"Recall\": 0.757, \"F1\": 0.779},\n",
    "        \"MaxEnt\": {\"AUC-ROC\": 0.837, \"Precision\": 0.336, \"Recall\": 0.636, \"F1\": 0.440},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Normalise weights across species\n",
    "for species in species_list:\n",
    "    model_weights = {}\n",
    "    for model in performance_metrics[species].keys():\n",
    "        # Compute an average of all normalised scores for balanced weighting\n",
    "        metrics = performance_metrics[species][model]\n",
    "        model_weights[model] = np.mean([metrics[\"AUC-ROC\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1\"]])\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    total_weight = sum(model_weights.values())\n",
    "    for model in model_weights.keys():\n",
    "        model_weights[model] /= total_weight  # Scale to sum up to 1\n",
    "\n",
    "    performance_metrics[species][\"Weights\"] = model_weights  # Store normalised weights\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    print(f\"üîç Computing weighted ensemble predictions for {species}...\")\n",
    "\n",
    "    # Load ensemble predictions file\n",
    "    file_path = os.path.join(ensemble_input_dir, f\"{species}_Ensemble_Predictions.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è Missing ensemble file for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify probability columns\n",
    "    probability_columns = [col for col in df.columns if col.endswith(\"_Probability\")]\n",
    "\n",
    "    if len(probability_columns) == 0:\n",
    "        print(f\"‚ö†Ô∏è No probability columns found for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Compute weighted ensemble probability\n",
    "    weighted_predictions = np.zeros(len(df))\n",
    "\n",
    "    for model in probability_columns:\n",
    "        model_name = model.replace(\"_Probability\", \"\")  # Extract model name\n",
    "        if model_name in performance_metrics[species][\"Weights\"]:\n",
    "            weighted_predictions += df[model] * performance_metrics[species][\"Weights\"][model_name]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing weight for {model_name} in {species}. Skipping.\")\n",
    "\n",
    "    df[\"Weighted_Ensemble\"] = weighted_predictions\n",
    "\n",
    "    # Save the final ensemble model as a function\n",
    "    def ensemble_prediction(input_data):\n",
    "        \"\"\"\n",
    "        Apply weighted ensemble model to new data.\n",
    "        :param input_data: DataFrame containing model probabilities as input features.\n",
    "        :return: Weighted probability scores.\n",
    "        \"\"\"\n",
    "        weighted_pred = np.zeros(len(input_data))\n",
    "        for model in probability_columns:\n",
    "            model_name = model.replace(\"_Probability\", \"\")\n",
    "            if model_name in performance_metrics[species]:\n",
    "                weighted_pred += input_data[model] * performance_metrics[species][model_name]\n",
    "        return weighted_pred\n",
    "\n",
    "    # Save the model using joblib\n",
    "    model_output_path = os.path.join(ensemble_output_dir, f\"{species}_Final_Ensemble_Model.pkl\")\n",
    "    joblib.dump(ensemble_prediction, model_output_path)\n",
    "\n",
    "    print(f\"‚úÖ Saved final ensemble model for {species} at {model_output_path}\")\n",
    "\n",
    "print(\"\\nüöÄ Weighted ensemble averaging complete! Ready for threshold selection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee003947-2763-4ecf-96e6-2f16f2724cea",
   "metadata": {},
   "source": [
    "### 3.3 Selecting the Optimal Threshold for Presence-Absence Classification\n",
    "\n",
    "Now that the weighted ensemble predictions have been generated, the next step is threshold selection, which converts probability predictions into binary presence/absence values. We have multiple options to determine the best threshold:\n",
    "\n",
    "#### 1. Maximising the F1-score:\n",
    "* The best balance between precision and recall.\n",
    "* Ideal if you want to avoid too many false positives or false negatives.\n",
    "\n",
    "#### 2. Maximising the Youden Index (J-Statistic):\n",
    "* The threshold that maximises (Sensitivity + Specificity - 1).\n",
    "* Ensures both presence and absence are well-classified.\n",
    "\n",
    "#### 3. Fixed Threshold (e.g., 0.5):\n",
    "* Simple but not species-specific.\n",
    "* May not be optimal given imbalanced data.\n",
    "\n",
    "All three methods will be implemented and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1762fd1-6db3-42fc-9da7-930de024650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Bufo bufo - Missing Values:\n",
      "True_Label              3870\n",
      "RF_Probability          3870\n",
      "XGBoost_Probability        0\n",
      "MaxEnt_Probability      2405\n",
      "Weighted_Probability    3870\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Cleaned and saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Bufo bufo_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "üîç Rana temporaria - Missing Values:\n",
      "True_Label              5994\n",
      "RF_Probability          5994\n",
      "XGBoost_Probability        0\n",
      "MaxEnt_Probability      2756\n",
      "Weighted_Probability    5994\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Cleaned and saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Rana temporaria_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "üîç Lissotriton helveticus - Missing Values:\n",
      "True_Label              1827\n",
      "RF_Probability          1827\n",
      "XGBoost_Probability        0\n",
      "MaxEnt_Probability       981\n",
      "Weighted_Probability    1827\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Cleaned and saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Lissotriton helveticus_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "üöÄ Data cleaning complete! Now re-run threshold selection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory for weighted ensemble predictions\n",
    "weighted_ensemble_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\"\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    file_path = os.path.join(weighted_ensemble_dir, f\"{species}_Weighted_Ensemble_Predictions.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è Missing weighted ensemble file for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Check for NaN values\n",
    "    nan_counts = df.isnull().sum()\n",
    "    print(f\"\\nüîç {species} - Missing Values:\\n{nan_counts}\\n\")\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Ensure True_Label is binary (0 or 1) and integer\n",
    "    df[\"True_Label\"] = df[\"True_Label\"].astype(int)\n",
    "\n",
    "    # Ensure Weighted_Probability is numeric\n",
    "    df[\"Weighted_Probability\"] = df[\"Weighted_Probability\"].astype(float)\n",
    "\n",
    "    # Save cleaned dataset\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"‚úÖ Cleaned and saved: {file_path}\")\n",
    "\n",
    "print(\"\\nüöÄ Data cleaning complete! Now re-run threshold selection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b52c299-6109-44e1-8e23-33d8212a871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Selecting threshold for Bufo bufo...\n",
      "‚úÖ Saved binary predictions for Bufo bufo at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Bufo bufo_Final_Binary_Predictions.csv\n",
      "üîç Selecting threshold for Rana temporaria...\n",
      "‚úÖ Saved binary predictions for Rana temporaria at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Rana temporaria_Final_Binary_Predictions.csv\n",
      "üîç Selecting threshold for Lissotriton helveticus...\n",
      "‚úÖ Saved binary predictions for Lissotriton helveticus at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Lissotriton helveticus_Final_Binary_Predictions.csv\n",
      "\n",
      "üöÄ Threshold selection complete! Ready for final evaluation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n",
    "\n",
    "# Define input/output directories\n",
    "weighted_ensemble_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\"\n",
    "binary_output_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\"\n",
    "os.makedirs(binary_output_dir, exist_ok=True)\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Function to find the best threshold using F1-score and Youden Index\n",
    "def find_best_threshold(y_true, y_pred_prob):\n",
    "    # Compute F1-score optimal threshold\n",
    "    precisions, recalls, thresholds_pr = precision_recall_curve(y_true, y_pred_prob)\n",
    "    f1_scores = (2 * precisions * recalls) / (precisions + recalls + 1e-9)  # Avoid division by zero\n",
    "    best_f1_threshold = thresholds_pr[np.argmax(f1_scores)]\n",
    "\n",
    "    # Compute Youden's J Index optimal threshold\n",
    "    fpr, tpr, thresholds_roc = roc_curve(y_true, y_pred_prob)\n",
    "    youden_index = tpr - fpr\n",
    "    best_youden_threshold = thresholds_roc[np.argmax(youden_index)]\n",
    "\n",
    "    return best_f1_threshold, best_youden_threshold\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    print(f\"üîç Selecting threshold for {species}...\")\n",
    "\n",
    "    # Load weighted ensemble predictions\n",
    "    file_path = os.path.join(weighted_ensemble_dir, f\"{species}_Weighted_Ensemble_Predictions.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è Missing weighted ensemble file for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"True_Label\" not in df.columns or \"Weighted_Probability\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Columns missing in {species} predictions. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    y_true = df[\"True_Label\"].values\n",
    "    y_pred_prob = df[\"Weighted_Probability\"].values\n",
    "\n",
    "    # Compute best thresholds\n",
    "    best_f1_threshold, best_youden_threshold = find_best_threshold(y_true, y_pred_prob)\n",
    "\n",
    "    # Apply thresholds to create binary presence/absence classifications\n",
    "    df[\"Binary_F1\"] = (df[\"Weighted_Probability\"] >= best_f1_threshold).astype(int)\n",
    "    df[\"Binary_Youden\"] = (df[\"Weighted_Probability\"] >= best_youden_threshold).astype(int)\n",
    "    df[\"Binary_0.5\"] = (df[\"Weighted_Probability\"] >= 0.5).astype(int)  # Fixed threshold\n",
    "\n",
    "    # Save binary classification results\n",
    "    output_file = os.path.join(binary_output_dir, f\"{species}_Final_Binary_Predictions.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Saved binary predictions for {species} at {output_file}\")\n",
    "\n",
    "print(\"\\nüöÄ Threshold selection complete! Ready for final evaluation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74ce20-1a19-48b7-97f1-9181ca8de9e4",
   "metadata": {},
   "source": [
    "### **Formal Evaluation of Thresholding Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5a72b0-ba78-4ebf-a41c-9e838e2ea534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating threshold methods for Bufo bufo...\n",
      "üîç Evaluating threshold methods for Rana temporaria...\n",
      "üîç Evaluating threshold methods for Lissotriton helveticus...\n",
      "\n",
      "üöÄ Threshold evaluation complete! Results saved at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Threshold_Evaluation.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Threshold_Method</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bufo bufo</td>\n",
       "      <td>Binary_F1</td>\n",
       "      <td>0.851972</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.764977</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.938967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bufo bufo</td>\n",
       "      <td>Binary_Youden</td>\n",
       "      <td>0.851972</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.764977</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.938967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bufo bufo</td>\n",
       "      <td>Binary_0.5</td>\n",
       "      <td>0.851972</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.764977</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.938967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rana temporaria</td>\n",
       "      <td>Binary_F1</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.899054</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.872894</td>\n",
       "      <td>0.903030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rana temporaria</td>\n",
       "      <td>Binary_Youden</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.960289</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.867863</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rana temporaria</td>\n",
       "      <td>Binary_0.5</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>0.917219</td>\n",
       "      <td>0.824405</td>\n",
       "      <td>0.868339</td>\n",
       "      <td>0.924242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lissotriton helveticus</td>\n",
       "      <td>Binary_F1</td>\n",
       "      <td>0.830014</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.901099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lissotriton helveticus</td>\n",
       "      <td>Binary_Youden</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lissotriton helveticus</td>\n",
       "      <td>Binary_0.5</td>\n",
       "      <td>0.825549</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.901099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Species Threshold_Method   AUC-ROC  Precision    Recall  \\\n",
       "0               Bufo bufo        Binary_F1  0.851972   0.927374  0.764977   \n",
       "1               Bufo bufo    Binary_Youden  0.851972   0.927374  0.764977   \n",
       "2               Bufo bufo       Binary_0.5  0.851972   0.927374  0.764977   \n",
       "3         Rana temporaria        Binary_F1  0.875622   0.899054  0.848214   \n",
       "4         Rana temporaria    Binary_Youden  0.879167   0.960289  0.791667   \n",
       "5         Rana temporaria       Binary_0.5  0.874324   0.917219  0.824405   \n",
       "6  Lissotriton helveticus        Binary_F1  0.830014   0.904255  0.758929   \n",
       "7  Lissotriton helveticus    Binary_Youden  0.840659   0.963855  0.714286   \n",
       "8  Lissotriton helveticus       Binary_0.5  0.825549   0.903226  0.750000   \n",
       "\n",
       "   F1-Score  Specificity  \n",
       "0  0.838384     0.938967  \n",
       "1  0.838384     0.938967  \n",
       "2  0.838384     0.938967  \n",
       "3  0.872894     0.903030  \n",
       "4  0.867863     0.966667  \n",
       "5  0.868339     0.924242  \n",
       "6  0.825243     0.901099  \n",
       "7  0.820513     0.967033  \n",
       "8  0.819512     0.901099  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define input directory\n",
    "binary_predictions_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\"\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Dictionary to store results\n",
    "evaluation_results = []\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    print(f\"üîç Evaluating threshold methods for {species}...\")\n",
    "    \n",
    "    # Load binary predictions\n",
    "    file_path = os.path.join(binary_predictions_dir, f\"{species}_Final_Binary_Predictions.csv\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è Missing binary predictions for {species}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract true labels\n",
    "    y_true = df[\"True_Label\"].values\n",
    "    \n",
    "    # Evaluate each thresholding method\n",
    "    for method in [\"Binary_F1\", \"Binary_Youden\", \"Binary_0.5\"]:\n",
    "        if method not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Missing {method} predictions for {species}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        y_pred = df[method].values\n",
    "        \n",
    "        # Compute evaluation metrics\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        # Store results\n",
    "        evaluation_results.append({\n",
    "            \"Species\": species,\n",
    "            \"Threshold_Method\": method,\n",
    "            \"AUC-ROC\": auc,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1,\n",
    "            \"Specificity\": specificity\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Save evaluation results\n",
    "evaluation_output_path = os.path.join(binary_predictions_dir, \"Threshold_Evaluation.csv\")\n",
    "eval_df.to_csv(evaluation_output_path, index=False)\n",
    "\n",
    "print(f\"\\nüöÄ Threshold evaluation complete! Results saved at {evaluation_output_path}\")\n",
    "\n",
    "# Display results\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444e2ec-d19a-4644-8642-c21ad4aeda68",
   "metadata": {},
   "source": [
    "In the ensemble modeling study, three **threshold selection** methods were evaluated ‚Äî maximizing the F1-score, maximizing the Youden Index (J-Statistic), and applying a fixed threshold of 0.5 ‚Äî to convert continuous probability predictions into binary presence-absence classifications for three amphibian species: *Bufo bufo*, *Rana temporaria*, and *Lissotriton helveticus*.\n",
    "\n",
    "The evaluation metrics‚ÄîAUC-ROC, Precision, Recall, F1-Score, and Specificity‚Äîare closely aligned across the three threshold methods for each species. This similarity suggests that the choice of threshold method may have a limited impact on the binary classification outcomes in the study's specific case.\n",
    "\n",
    "Given these findings, a fixed threshold of 0.5 for converting probability predictions into binary classifications will be adopted. This approach offers simplicity and consistency across species, facilitating straightforward interpretation and application in conservation efforts (Liu et al., 2013)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6cad3-2a12-4379-8b2e-82783d2232d1",
   "metadata": {},
   "source": [
    "## 4. Compute Final Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ea2799-c716-40a3-a64d-f5db371c0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating final model for Bufo bufo...\n",
      "‚úÖ Confusion matrix saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Bufo bufo_Confusion_Matrix.png\n",
      "üîç Evaluating final model for Rana temporaria...\n",
      "‚úÖ Confusion matrix saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Rana temporaria_Confusion_Matrix.png\n",
      "üîç Evaluating final model for Lissotriton helveticus...\n",
      "‚úÖ Confusion matrix saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Lissotriton helveticus_Confusion_Matrix.png\n",
      "\n",
      "üöÄ Final model evaluation complete! Results saved at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Final_Evaluation.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bufo bufo</td>\n",
       "      <td>0.851972</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.764977</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.851163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rana temporaria</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>0.917219</td>\n",
       "      <td>0.824405</td>\n",
       "      <td>0.868339</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.873874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lissotriton helveticus</td>\n",
       "      <td>0.825549</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.817734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Species   AUC-ROC  Precision    Recall  F1-Score  \\\n",
       "0               Bufo bufo  0.851972   0.927374  0.764977  0.838384   \n",
       "1         Rana temporaria  0.874324   0.917219  0.824405  0.868339   \n",
       "2  Lissotriton helveticus  0.825549   0.903226  0.750000  0.819512   \n",
       "\n",
       "   Specificity  Accuracy  \n",
       "0     0.938967  0.851163  \n",
       "1     0.924242  0.873874  \n",
       "2     0.901099  0.817734  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, accuracy_score\n",
    ")\n",
    "\n",
    "# Define input/output directories\n",
    "binary_predictions_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\"\n",
    "evaluation_output_path = os.path.join(binary_predictions_dir, \"Final_Evaluation.csv\")\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Initialise dataframe for storing evaluation results\n",
    "evaluation_results = []\n",
    "\n",
    "# Function to compute specificity\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    print(f\"üîç Evaluating final model for {species}...\")\n",
    "\n",
    "    # Load final binary predictions\n",
    "    file_path = os.path.join(binary_predictions_dir, f\"{species}_Final_Binary_Predictions.csv\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è Missing binary predictions for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"True_Label\" not in df.columns or \"Binary_0.5\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Columns missing in {species} predictions. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Extract true labels and binary predictions at threshold 0.5\n",
    "    y_true = df[\"True_Label\"].values\n",
    "    y_pred = df[\"Binary_0.5\"].values\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    specificity = specificity_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    evaluation_results.append({\n",
    "        \"Species\": species,\n",
    "        \"AUC-ROC\": auc_roc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "    # Generate and save confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Absence\", \"Presence\"], yticklabels=[\"Absence\", \"Presence\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix - {species}\")\n",
    "\n",
    "    cm_output_path = os.path.join(binary_predictions_dir, f\"{species}_Confusion_Matrix.png\")\n",
    "    plt.savefig(cm_output_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Confusion matrix saved: {cm_output_path}\")\n",
    "\n",
    "# Convert results to dataframe\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Save final evaluation results\n",
    "evaluation_df.to_csv(evaluation_output_path, index=False)\n",
    "print(f\"\\nüöÄ Final model evaluation complete! Results saved at {evaluation_output_path}\")\n",
    "\n",
    "# Display results in JupyterLab\n",
    "display(evaluation_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281ad5e-921c-44c3-91c8-3244ef875cc3",
   "metadata": {},
   "source": [
    "## 5. Ensemble Model Evaluation\n",
    "\n",
    "### 1. Are the Results Aligned with the Study Objectives?\n",
    "\n",
    "Yes, overall, the ensemble model has achieved strong predictive performance across all three species (Bufo bufo, Rana temporaria, Lissotriton helveticus).\n",
    "The study's primary objectives included:\n",
    "1. Improving species distribution modelling (SDM) using an ensemble approach.\n",
    "2. Balancing false positives and false negatives to ensure robust habitat suitability predictions.\n",
    "3. Optimising predictive accuracy while maintaining ecological interpretability.\n",
    "\n",
    "#### Key Observations:\n",
    "* **High AUC-ROC across species (0.82 ‚Äì 0.87)**: Indicates strong discriminatory power of the final model.\n",
    "* **Balanced Precision & Recall**: Suggests that the model is not heavily biased towards either false positives or false negatives.\n",
    "* **Consistent Accuracy (~82‚Äì87%)**: Demonstrates a reliable overall classification of presence vs absence.\n",
    "\n",
    "### 2. Are the Evaluation Metrics Satisfactory for All Species?\n",
    "Overall, the evaluation metrics are strong, but some species perform better than others:\n",
    "\n",
    "#### *Bufo bufo* and *Rana temporaria*:\n",
    "* High AUC-ROC, high precision, and balanced recall.\n",
    "* Precision is consistently high (~0.90+) ‚Üí The model is good at avoiding false positives.\n",
    "* Balanced recall values ‚Üí Indicates that most true presences are detected.\n",
    "  \n",
    "#### *Lissotriton helveticus*:\n",
    "\n",
    "* Lowest Recall (0.75) ‚Üí Suggests that a higher proportion of actual presences may be misclassified as absences.\n",
    "* Slightly lower AUC-ROC (0.826) compared to other species.\n",
    "* However, Precision remains high (0.903), meaning the model correctly identifies presences when it predicts them.\n",
    "\n",
    "### 3. Are There Any Species Where Performance is Lower Than Expected?\n",
    "\n",
    "***Lissotriton helveticus*** is the weakest-performing species, particularly in recall (0.750). This means the model underpredicts some true presences, which could be problematic for conservation-focused applications. Possible Reasons for Lower Recall in *Lissotriton helveticus*:\n",
    "\n",
    "* Lower **Sample Size**\n",
    "* More **Fragmented Distribution**\n",
    "* Environmental **Predictors** May Not Capture Key Ecological Factors: Amphibian distribution is influenced by microhabitats, which may not be fully represented in the predictor variables used.\n",
    "* **MaxEnt‚Äôs Lower Performance** for This Species: MaxEnt had lower precision and recall across models, and its inclusion in the weighted ensemble may have pulled down overall recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80e37d-1cc1-4314-ab00-ea5188fb4772",
   "metadata": {},
   "source": [
    "## 6. Conclusion and Next Steps\n",
    "\n",
    "1. For **Overall Ensemble Model**:\n",
    "* Move forward with spatial mapping to ensure results align ecologically.\n",
    "* Compare species-specific habitat suitability maps and validate against known ecological expectations.\n",
    "\n",
    "2. For ***Lissotriton helveticus***: The study might consider inspecting misclassified presence points in GIS to adjust mapped distribution.\n",
    "Potential investigation on whether key predictor variables (e.g., distance to ponds, canopy cover) need refinement.\n",
    "If recall remains a concern, threshold selection method could be adjusted to prioritise higher recall (i.e., optimising for Youden‚Äôs Index instead of F1-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ed00c-2b22-41bf-bf2a-b5febb6500a7",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "Liu, C., White, M., & Newell, G. (2013). Selecting thresholds for the prediction of species occurrence with presence-only data. *Journal of Biogeography*, 40(4), 778‚Äì789. https://doi.org/10.1111/jbi.12058\n",
    "\n",
    "Meller, L., Cabeza, M., Pironon, S., Barbet-Massin, M., Maiorano, L., Georges, D., & Thuiller, W. (2014). Ensemble distribution models in conservation prioritization: From consensus predictions to consensus reserve networks. *Diversity and Distributions*, 20(3), 309‚Äì321. https://doi.org/10.1111/ddi.12162\n",
    "\n",
    "Ramirez-Reyes, C., Nazeri, M., Street, G., Jones-Farrand, D. T., Vilella, F. J., & Evans, K. O. (2021). Embracing ensemble species distribution models to inform at-risk species status assessments. *Journal of Fish and Wildlife Management*, 12(1), 98‚Äì111. https://doi.org/10.3996/JFWM-20-072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c485ca-6fda-4bc7-a649-ef1bd37004a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
