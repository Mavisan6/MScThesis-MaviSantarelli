{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9286228-765d-4082-a911-b3cf2acea5a0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction and Objectives](#1.-Introduction-and-Objectives)\n",
    "2. [Import Required Libraries and Datasets](#2.-Import-Required-Libraries-and-Datasets)\n",
    "3. [GLM Model Training](#3.1-GLM-Model-Training)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c36751-b697-4ed1-83dc-a2c3d648723c",
   "metadata": {},
   "source": [
    "## 1. Introduction and Objectives\n",
    "### 1.1 Introduction\n",
    "Species distribution models (SDMs) are a key tool for understanding the relationship between species occurrences and environmental factors. They provide a means to predict species distributions across geographic areas and under varying environmental conditions. This notebook focuses on the **model training and evaluation** step, which is a critical phase in building robust SDMs. By using subsampled datasets, tailored to specific model requirements, we aim to generate accurate and ecologically meaningful predictions.\n",
    "\n",
    "The modelling process will include a combination of regression-based approaches (GLM and GAM), machine learning models (Random Forest and XGBoost), and a presence-only method (Maxent). Each model has unique strengths, making it suitable for capturing different aspects of species-environment interactions.\n",
    "\n",
    "### 1.2 Objectives\n",
    "##### 1. **Train Species Distribution Models**:\n",
    "   - Utilise subsampled datasets prepared in the previous step for each species (*Bufo bufo*, *Rana temporaria*, and *Lissotriton helveticus*).\n",
    "   - Implement models specific to each approach:\n",
    "     - **Generalised Linear Models (GLM)**\n",
    "     - **Generalised Additive Models (GAM)**\n",
    "     - **Random Forest (RF)**\n",
    "     - **XGBoost**\n",
    "     - **Maxent**\n",
    "\n",
    "##### 2. **Evaluate Model Performance**:\n",
    "   - Assess model accuracy and predictive power using metrics such as:\n",
    "     - Area Under the Curve (AUC)\n",
    "     - Accuracy\n",
    "     - Sensitivity and Specificity\n",
    "     - Confusion Matrix\n",
    "\n",
    "##### 3. **Incorporate Iterative Modelling for Machine Learning Approaches**:\n",
    "   - Perform 10 iterations for Random Forest and XGBoost, averaging predictions to ensure model stability and reduce variability.\n",
    "\n",
    "##### 4. **Save Results and Outputs**:\n",
    "   - Save trained models, evaluation metrics, and predictions for further analysis.\n",
    "   - Export visualisations such as variable importance plots and ROC curves.\n",
    "\n",
    "### 1.3 Expected Outcome\n",
    "By the end of this notebook:\n",
    "- Robust models will be trained for each species and model type.\n",
    "- Performance metrics will provide insights into the predictive capacity of each approach.\n",
    "- Outputs will form the basis for ecological interpretation, spatial predictions, and conservation recommendations.\n",
    "\n",
    "This phase builds upon the carefully prepared datasets, ensuring that the models align with ecological principles and established methodologies in SDMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510cbaf-ae93-4cb5-b34c-25de86af0f23",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries and Datasets\n",
    "\n",
    "### 2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc455567-25db-48b1-b942-4681eedcffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from pygam import GAM, s, f\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib  # For saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014d89c-784b-4170-9aaa-d6df43d04f14",
   "metadata": {},
   "source": [
    "### 2.2 Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43603218-ea0a-4a0b-860d-84aebe0ea967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data for Bufo bufo...\n",
      "  Loading training data for model: GLM...\n",
      "  Loading training data for model: GAM...\n",
      "  Loading training data for model: Maxent...\n",
      "  Loading training data for model: RF...\n",
      "  Loading training data for model: XGBoost...\n",
      "Loading training data for Rana temporaria...\n",
      "  Loading training data for model: GLM...\n",
      "  Loading training data for model: GAM...\n",
      "  Loading training data for model: Maxent...\n",
      "  Loading training data for model: RF...\n",
      "  Loading training data for model: XGBoost...\n",
      "Loading training data for Lissotriton helveticus...\n",
      "  Loading training data for model: GLM...\n",
      "  Loading training data for model: GAM...\n",
      "  Loading training data for model: Maxent...\n",
      "  Loading training data for model: RF...\n",
      "  Loading training data for model: XGBoost...\n",
      "\n",
      "Training data loaded for Bufo bufo:\n",
      "  GLM: Single training dataset loaded\n",
      "  GAM: Single training dataset loaded\n",
      "  Maxent: Single training dataset loaded\n",
      "  RF: 10 iterations of training data loaded\n",
      "  XGBoost: 10 iterations of training data loaded\n",
      "\n",
      "Training data loaded for Rana temporaria:\n",
      "  GLM: Single training dataset loaded\n",
      "  GAM: Single training dataset loaded\n",
      "  Maxent: Single training dataset loaded\n",
      "  RF: 10 iterations of training data loaded\n",
      "  XGBoost: 10 iterations of training data loaded\n",
      "\n",
      "Training data loaded for Lissotriton helveticus:\n",
      "  GLM: Single training dataset loaded\n",
      "  GAM: Single training dataset loaded\n",
      "  Maxent: Single training dataset loaded\n",
      "  RF: 10 iterations of training data loaded\n",
      "  XGBoost: 10 iterations of training data loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths for training data only (partitioned data)\n",
    "partitioned_train_files = {\n",
    "    \"Bufo bufo\": {\n",
    "        \"GLM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_GLM_subsampled_train.csv\",\n",
    "        \"GAM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_GAM_subsampled_train.csv\",\n",
    "        \"Maxent\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_Maxent_subsampled_train.csv\",\n",
    "        \"RF\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_RF_subsampled_run{i}_train.csv\" for i in range(1, 11)],\n",
    "        \"XGBoost\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_XGBoost_subsampled_run{i}_train.csv\" for i in range(1, 11)]\n",
    "    },\n",
    "    \"Rana temporaria\": {\n",
    "        \"GLM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_GLM_subsampled_train.csv\",\n",
    "        \"GAM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_GAM_subsampled_train.csv\",\n",
    "        \"Maxent\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_Maxent_subsampled_train.csv\",\n",
    "        \"RF\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_RF_subsampled_run{i}_train.csv\" for i in range(1, 11)],\n",
    "        \"XGBoost\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_XGBoost_subsampled_run{i}_train.csv\" for i in range(1, 11)]\n",
    "    },\n",
    "    \"Lissotriton helveticus\": {\n",
    "        \"GLM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_GLM_subsampled_train.csv\",\n",
    "        \"GAM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_GAM_subsampled_train.csv\",\n",
    "        \"Maxent\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_Maxent_subsampled_train.csv\",\n",
    "        \"RF\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_RF_subsampled_run{i}_train.csv\" for i in range(1, 11)],\n",
    "        \"XGBoost\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_XGBoost_subsampled_run{i}_train.csv\" for i in range(1, 11)]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load the training data for each species and model into a dictionary\n",
    "loaded_train_data = {}\n",
    "\n",
    "for species, models in partitioned_train_files.items():\n",
    "    print(f\"Loading training data for {species}...\")\n",
    "    loaded_train_data[species] = {}\n",
    "    \n",
    "    for model_name, file_paths in models.items():\n",
    "        print(f\"  Loading training data for model: {model_name}...\")\n",
    "        \n",
    "        # Handle single-file models (GLM, GAM, Maxent)\n",
    "        if isinstance(file_paths, str):  # Single file for training\n",
    "            loaded_train_data[species][model_name] = pd.read_csv(file_paths)\n",
    "        else:  # Handle iterative models (RF, XGBoost)\n",
    "            loaded_train_data[species][model_name] = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Verify the structure of the loaded training data\n",
    "for species, models in loaded_train_data.items():\n",
    "    print(f\"\\nTraining data loaded for {species}:\")\n",
    "    for model_name, data in models.items():\n",
    "        if isinstance(data, list):\n",
    "            print(f\"  {model_name}: {len(data)} iterations of training data loaded\")\n",
    "        else:\n",
    "            print(f\"  {model_name}: Single training dataset loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b39108-aacb-4a72-885e-d74d7410c6d7",
   "metadata": {},
   "source": [
    "### 2.3 Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3aa22dd-12d1-4aca-a172-f00c97e51d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data for Bufo bufo...\n",
      "  Loading test data for model: GLM...\n",
      "  Loading test data for model: GAM...\n",
      "  Loading test data for model: Maxent...\n",
      "  Loading test data for model: RF...\n",
      "  Loading test data for model: XGBoost...\n",
      "Loading test data for Rana temporaria...\n",
      "  Loading test data for model: GLM...\n",
      "  Loading test data for model: GAM...\n",
      "  Loading test data for model: Maxent...\n",
      "  Loading test data for model: RF...\n",
      "  Loading test data for model: XGBoost...\n",
      "Loading test data for Lissotriton helveticus...\n",
      "  Loading test data for model: GLM...\n",
      "  Loading test data for model: GAM...\n",
      "  Loading test data for model: Maxent...\n",
      "  Loading test data for model: RF...\n",
      "  Loading test data for model: XGBoost...\n",
      "\n",
      "Test data loaded for Bufo bufo:\n",
      "  GLM: Single test dataset loaded\n",
      "  GAM: Single test dataset loaded\n",
      "  Maxent: Single test dataset loaded\n",
      "  RF: 10 iterations of test data loaded\n",
      "  XGBoost: 10 iterations of test data loaded\n",
      "\n",
      "Test data loaded for Rana temporaria:\n",
      "  GLM: Single test dataset loaded\n",
      "  GAM: Single test dataset loaded\n",
      "  Maxent: Single test dataset loaded\n",
      "  RF: 10 iterations of test data loaded\n",
      "  XGBoost: 10 iterations of test data loaded\n",
      "\n",
      "Test data loaded for Lissotriton helveticus:\n",
      "  GLM: Single test dataset loaded\n",
      "  GAM: Single test dataset loaded\n",
      "  Maxent: Single test dataset loaded\n",
      "  RF: 10 iterations of test data loaded\n",
      "  XGBoost: 10 iterations of test data loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths for test data only (partitioned data)\n",
    "partitioned_test_files = {\n",
    "    \"Bufo bufo\": {\n",
    "        \"GLM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_GLM_subsampled_test.csv\",\n",
    "        \"GAM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_GAM_subsampled_test.csv\",\n",
    "        \"Maxent\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_Maxent_subsampled_test.csv\",\n",
    "        \"RF\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_RF_subsampled_run{i}_test.csv\" for i in range(1, 11)],\n",
    "        \"XGBoost\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Bufo bufo_XGBoost_subsampled_run{i}_test.csv\" for i in range(1, 11)]\n",
    "    },\n",
    "    \"Rana temporaria\": {\n",
    "        \"GLM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_GLM_subsampled_test.csv\",\n",
    "        \"GAM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_GAM_subsampled_test.csv\",\n",
    "        \"Maxent\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_Maxent_subsampled_test.csv\",\n",
    "        \"RF\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_RF_subsampled_run{i}_test.csv\" for i in range(1, 11)],\n",
    "        \"XGBoost\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Rana temporaria_XGBoost_subsampled_run{i}_test.csv\" for i in range(1, 11)]\n",
    "    },\n",
    "    \"Lissotriton helveticus\": {\n",
    "        \"GLM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_GLM_subsampled_test.csv\",\n",
    "        \"GAM\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_GAM_subsampled_test.csv\",\n",
    "        \"Maxent\": \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_Maxent_subsampled_test.csv\",\n",
    "        \"RF\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_RF_subsampled_run{i}_test.csv\" for i in range(1, 11)],\n",
    "        \"XGBoost\": [f\"C:/GIS_Course/MScThesis-MaviSantarelli/data/Partitioned/Lissotriton helveticus_XGBoost_subsampled_run{i}_test.csv\" for i in range(1, 11)]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load the test data for each species and model into a dictionary\n",
    "loaded_test_data = {}\n",
    "\n",
    "for species, models in partitioned_test_files.items():\n",
    "    print(f\"Loading test data for {species}...\")\n",
    "    loaded_test_data[species] = {}\n",
    "    \n",
    "    for model_name, file_paths in models.items():\n",
    "        print(f\"  Loading test data for model: {model_name}...\")\n",
    "        \n",
    "        # Handle single-file models (GLM, GAM, Maxent)\n",
    "        if isinstance(file_paths, str):  # Single file for test\n",
    "            loaded_test_data[species][model_name] = pd.read_csv(file_paths)\n",
    "        else:  # Handle iterative models (RF, XGBoost)\n",
    "            loaded_test_data[species][model_name] = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Verify the structure of the loaded test data\n",
    "for species, models in loaded_test_data.items():\n",
    "    print(f\"\\nTest data loaded for {species}:\")\n",
    "    for model_name, data in models.items():\n",
    "        if isinstance(data, list):\n",
    "            print(f\"  {model_name}: {len(data)} iterations of test data loaded\")\n",
    "        else:\n",
    "            print(f\"  {model_name}: Single test dataset loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a58a6b-b2af-42d1-8cb6-4efa12cf4348",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "### **3.1 GLM Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14f489c8-d22e-49ca-bb78-3dd635629cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GLM for Bufo bufo...\n",
      "  ROC-AUC for Bufo bufo: 0.828\n",
      "  Confusion Matrix:\n",
      "[[1178    8]\n",
      " [ 135    6]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1186\n",
      "           1       0.43      0.04      0.08       141\n",
      "\n",
      "    accuracy                           0.89      1327\n",
      "   macro avg       0.66      0.52      0.51      1327\n",
      "weighted avg       0.85      0.89      0.85      1327\n",
      "\n",
      "  Model saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Bufo bufo_GLM_Model.pkl\n",
      "  Metrics saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Bufo bufo_GLM_Metrics.txt\n",
      "Training GLM for Rana temporaria...\n",
      "  ROC-AUC for Rana temporaria: 0.820\n",
      "  Confusion Matrix:\n",
      "[[2465   23]\n",
      " [ 209   36]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2488\n",
      "           1       0.61      0.15      0.24       245\n",
      "\n",
      "    accuracy                           0.92      2733\n",
      "   macro avg       0.77      0.57      0.60      2733\n",
      "weighted avg       0.89      0.92      0.89      2733\n",
      "\n",
      "  Model saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Rana temporaria_GLM_Model.pkl\n",
      "  Metrics saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Rana temporaria_GLM_Metrics.txt\n",
      "Training GLM for Lissotriton helveticus...\n",
      "  ROC-AUC for Lissotriton helveticus: 0.809\n",
      "  Confusion Matrix:\n",
      "[[663   0]\n",
      " [ 70   1]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       663\n",
      "           1       1.00      0.01      0.03        71\n",
      "\n",
      "    accuracy                           0.90       734\n",
      "   macro avg       0.95      0.51      0.49       734\n",
      "weighted avg       0.91      0.90      0.86       734\n",
      "\n",
      "  Model saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Lissotriton helveticus_GLM_Model.pkl\n",
      "  Metrics saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Lissotriton helveticus_GLM_Metrics.txt\n",
      "GLM training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "# Directory to save results\n",
    "output_dir = \"C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each species for GLM training\n",
    "for species in loaded_train_data.keys():\n",
    "    print(f\"Training GLM for {species}...\")\n",
    "\n",
    "    # Get the GLM training dataset for the species\n",
    "    data = loaded_train_data[species][\"GLM\"]\n",
    "    X = data.drop(columns=[\"label\"])  # Predictors\n",
    "    y = data[\"label\"]  # Response variable (presence/absence)\n",
    "\n",
    "    # Split the data into training (70%) and testing (30%) subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train the GLM (Logistic Regression)\n",
    "    glm = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    glm.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = glm.predict(X_test)\n",
    "    y_pred_prob = glm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"  ROC-AUC for {species}: {roc_auc:.3f}\")\n",
    "    print(f\"  Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"  Classification Report:\\n{class_report}\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for {species} (GLM)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{output_dir}/{species}_GLM_ROC_Curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{output_dir}/{species}_GLM_Model.pkl\"\n",
    "    joblib.dump(glm, model_path)\n",
    "    print(f\"  Model saved for {species} at {model_path}\")\n",
    "\n",
    "    # Save evaluation metrics\n",
    "    metrics_path = f\"{output_dir}/{species}_GLM_Metrics.txt\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(f\"ROC-AUC: {roc_auc:.3f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{class_report}\\n\")\n",
    "    print(f\"  Metrics saved for {species} at {metrics_path}\")\n",
    "\n",
    "print(\"GLM training and evaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d2868-87ef-4579-8938-34feebd69628",
   "metadata": {},
   "source": [
    "## **Summary of GLM Results**\r\n",
    "\r\n",
    "### Bufo bufo\r\n",
    "- **ROC-AUC**: 0.828 (Good discriminatory power)\r\n",
    "- **Precision (label=1)**: 0.43\r\n",
    "- **Recall (label=1)**: 0.04 (Low, indicating a high number of false negatives)\r\n",
    "- **Overall Accuracy**: 0.89\r\n",
    "- **Notes**: The model performs well in predicting absences but struggles to accurately predict presences, leading to low sensitivity. Adjustments may be necessary to improve recall.\r\n",
    "\r\n",
    "### Rana temporaria\r\n",
    "- **ROC-AUC**: 0.820 (Good discriminatory power)\r\n",
    "- **Precision (label=1)**: 0.61\r\n",
    "- **Recall (label=1)**: 0.15 (Low recall, but better than *Bufo bufo*)\r\n",
    "- **Overall Accuracy**: 0.92\r\n",
    "- **Notes**: The model shows strong performance but is still biased towards predicting absences. Improvements to increase sensitivity to presences could further enhance results.\r\n",
    "\r\n",
    "### Lissotriton helveticus\r\n",
    "- **ROC-AUC**: 0.809 (Good discriminatory power)\r\n",
    "- **Precision (label=1)**: 1.00\r\n",
    "- **Recall (label=1)**: 0.01 (Very low recall)\r\n",
    "- **Overall Accuracy**: 0.90\r\n",
    "- **Notes**: Similar to *Bufo bufo*, the model is effective at predicting absences but struggles significantly to identify presences. This highlights a strong class imbalance in predictions.\r\n",
    "\r\n",
    "## Overall Observations\r\n",
    "- **Strengths**:\r\n",
    "  - All models show good overall discriminatory power (ROC-AUC > 0.8).\r\n",
    "  - High accuracy, primarily driven by correct absence predictions.\r\n",
    "- **Weaknesses**:\r\n",
    "  - All models exhibit low recall for presences, indicating challenges in correctly identifying presence points.\r\n",
    "  - Imbalanced datasets may have influenced these results, leading to models biased towards absences.\r\n",
    "\r\n",
    "## **Recommendations for Improvement**\r\n",
    "\r\n",
    "- **Address Class Imbalance**:\r\n",
    "  - Oversample presences or undersample absences to balance the dataset.\r\n",
    "- **Feature Analysis**:\r\n",
    "  - Evaluate feature importance to identify and remove less relevant predictors.\r\n",
    "- **Model Refinements**:\r\n",
    "  - Perform hyperparameter tuning for the logistic regression model (e.g., penalty type, solver).\r\n",
    "- **Iterate on Metrics**:\r\n",
    "  - Focus on improving recall and F1-score for presence predictions to create more balanced models.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff6c8e-99d1-40a9-92bc-9cf52a3a3e22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a727240-964a-4f1c-a75b-139113699c03",
   "metadata": {},
   "source": [
    "### Step 1: Address Class Imbalance\n",
    "Use `class_weight='balanced'` to improve recall for the minority class. This will ensure the presences are given more importance during training.\n",
    "\n",
    "#### **Rationale**:\n",
    "\n",
    "#### 1. Dynamic Weight Assignment\n",
    "The `class_weight='balanced'` parameter dynamically assigns weights to classes (presence and pseudo-absence) based on their frequency in the training data. This approach ensures that the minority class (presence) is given more influence during training, effectively improving recall for presences while maintaining a balance between the contributions of pseudo-absences and presences.\n",
    "\n",
    "#### 2. Minimising Overfitting to the Majority Class\n",
    "Without class weighting, logistic regression models tend to focus disproportionately on the majority class (pseudo-absences), which dominates the dataset. This imbalance leads to poor recall for presences and a higher false-negative rate. By implementing `class_weight='balanced'`, the issue is mitigated as the model's loss function adjusts for the unequal class distribution, enhancing its ability to detect presences accurately.\n",
    "\n",
    "#### 3. Compatibility with Logistic Regression\n",
    "Logistic regression, as a linear model, can face challenges with imbalanced datasets, often underperforming on the minority class. The `class_weight='balanced'` parameter is designed to address this limitation by ensuring that the imbalance in class frequencies does not overly influence the model's decision boundary, resulting in a more robust and fairer classification.\n",
    "\n",
    "#### 4. Alignment with Pseudo-Absence Generation Strategy\n",
    "The pseudo-absence generation methodology, which incorporates ecological buffers, already reduces potential biases in the absence data. Applying class weighting further complements this strategy by addressing statistical imbalances between presences and pseudo-absences. This combined approach ensures that the logistic regression model is optimised for the specific characteristics of the dataset without introducing additional ecological or statistical biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "777245c7-1d00-4222-afcd-9279e3760779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GLM for Bufo bufo...\n",
      "  ROC-AUC for Bufo bufo: 0.829\n",
      "  Confusion Matrix:\n",
      "[[859 327]\n",
      " [ 30 111]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      1186\n",
      "           1       0.25      0.79      0.38       141\n",
      "\n",
      "    accuracy                           0.73      1327\n",
      "   macro avg       0.61      0.76      0.61      1327\n",
      "weighted avg       0.89      0.73      0.78      1327\n",
      "\n",
      "  Model saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Bufo bufo_GLM_Model.pkl\n",
      "  Metrics saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Bufo bufo_GLM_Metrics.txt\n",
      "Training GLM for Rana temporaria...\n",
      "  ROC-AUC for Rana temporaria: 0.819\n",
      "  Confusion Matrix:\n",
      "[[1994  494]\n",
      " [  73  172]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88      2488\n",
      "           1       0.26      0.70      0.38       245\n",
      "\n",
      "    accuracy                           0.79      2733\n",
      "   macro avg       0.61      0.75      0.63      2733\n",
      "weighted avg       0.90      0.79      0.83      2733\n",
      "\n",
      "  Model saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Rana temporaria_GLM_Model.pkl\n",
      "  Metrics saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Rana temporaria_GLM_Metrics.txt\n",
      "Training GLM for Lissotriton helveticus...\n",
      "  ROC-AUC for Lissotriton helveticus: 0.809\n",
      "  Confusion Matrix:\n",
      "[[497 166]\n",
      " [ 19  52]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.75      0.84       663\n",
      "           1       0.24      0.73      0.36        71\n",
      "\n",
      "    accuracy                           0.75       734\n",
      "   macro avg       0.60      0.74      0.60       734\n",
      "weighted avg       0.89      0.75      0.80       734\n",
      "\n",
      "  Model saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Lissotriton helveticus_GLM_Model.pkl\n",
      "  Metrics saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Lissotriton helveticus_GLM_Metrics.txt\n",
      "GLM training and evaluation with class imbalance correction complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "# Directory to save results\n",
    "output_dir = \"C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each species for GLM training\n",
    "for species in loaded_train_data.keys():\n",
    "    print(f\"Training GLM for {species}...\")\n",
    "\n",
    "    # Get the GLM training dataset for the species\n",
    "    data = loaded_train_data[species][\"GLM\"]\n",
    "    X = data.drop(columns=[\"label\"])  # Predictors\n",
    "    y = data[\"label\"]  # Response variable (presence/absence)\n",
    "\n",
    "    # Split the data into training (70%) and testing (30%) subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train the GLM with class_weight='balanced' to address class imbalance\n",
    "    glm = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "    glm.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = glm.predict(X_test)\n",
    "    y_pred_prob = glm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"  ROC-AUC for {species}: {roc_auc:.3f}\")\n",
    "    print(f\"  Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"  Classification Report:\\n{class_report}\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for {species} (GLM)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{output_dir}/{species}_GLM_ROC_Curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{output_dir}/{species}_GLM_Model.pkl\"\n",
    "    joblib.dump(glm, model_path)\n",
    "    print(f\"  Model saved for {species} at {model_path}\")\n",
    "\n",
    "    # Save evaluation metrics\n",
    "    metrics_path = f\"{output_dir}/{species}_GLM_Metrics.txt\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(f\"ROC-AUC: {roc_auc:.3f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{class_report}\\n\")\n",
    "    print(f\"  Metrics saved for {species} at {metrics_path}\")\n",
    "\n",
    "print(\"GLM training and evaluation with class imbalance correction complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a27c6c-23da-4a2d-b216-ecd8593fcbe2",
   "metadata": {},
   "source": [
    "## **Summary of GLM Results and Observations**\r\n",
    "\r\n",
    "### Overview\r\n",
    "The Generalised Linear Models (GLM) were trained and evaluated for each species using class imbalance correction (`class_weight='balanced'`). The results show significant improvement in recall for the minority class (presences). However, there is still room for improvement, especially in precision for presences. The models performed better at predicting absences but struggled with correctly identifying presences.\r\n",
    "\r\n",
    "### General Observations\r\n",
    "##### 1. **Improved Recall**:\r\n",
    " - The class imbalance adjustment significantly improved recall for presences, achieving the following recall scores:\r\n",
    "   - **Bufo bufo**: 0.79\r\n",
    "   - **Rana temporaria**: 0.70\r\n",
    "   - **Lissotriton helveticus**: 0.73\r\n",
    " - Accurate identification of presences is crucial for species distribution modeling, and the increased recall helps meet this ecological objective.\r\n",
    "\r\n",
    "##### 2. **Low Precision for Presences**:\r\n",
    " - All models exhibit low precision for presences, indicating a high rate of false positives. Specifically:\r\n",
    "   - **Bufo bufo**: Precision for presences = 0.25\r\n",
    "   - **Rana temporaria**: Precision for presences = 0.26\r\n",
    "   - **Lissotriton helveticus**: Precision for presences = 0.24\r\n",
    " - This means the models overestimate the presence of species, which could lead to an inflated estimate of the species' potential range.\r\n",
    "\r\n",
    "##### 3. **Strong ROC-AUC Scores**:\r\n",
    " - The models consistently achieved **good ROC-AUC scores**:\r\n",
    "   - **Bufo bufo**: 0.829\r\n",
    "   - **Rana temporaria**: 0.819\r\n",
    "   - **Lissotriton helveticus**: 0.809\r\n",
    " - These scores demonstrate strong overall performance, with the models being effective in distinguishing between presence and absence.\r\n",
    "\r\n",
    "### Required Adjustments\r\n",
    "To further refine the models and improve their performance, the following steps will be performed:\r\n",
    "\r\n",
    "##### 1. **Threshold Adjustment**:\r\n",
    " - Adjust the decision threshold (default is 0.5) to better balance precision and recall for presences.\r\n",
    " - Generate **precision-recall curves** to identify the optimal threshold for minimizing false positives while maintaining good recall.\r\n",
    "\r\n",
    "##### 2. **Hyperparameter Tuning**:\r\n",
    " - Experiment with the **regularisation strength (`C`)** in logistic regression to further optimise performance, particularly for improving precision.\r\n",
    " \r\n",
    "##### 3. **Feature Selection**:\r\n",
    " - Reassess the **predictors** used in the model and exclude less informative variables to reduce noise and improve model robustness.\r\n",
    "\r\n",
    "##### 4. **Precision-Recall Trade-Offs**:\r\n",
    " - Evaluate precision-recall trade-offs in ecological applications, where false positives and false negatives may have different ecological consequences. This will help identify an acceptable trade-off betweents or if you need help with the next steps!\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11878bee-81f8-460f-a0a9-ac781f6bdb4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f757c-96bd-4819-af3d-4cffe7275373",
   "metadata": {},
   "source": [
    "### Step 2: Addressing multicollinearity\n",
    "\n",
    "Addressing multicollinearity is the next most important step after tackling class imbalances, especially for models like logistic regression (GLM) that are sensitive to highly correlated predictors. Here's why:\n",
    "\n",
    "1. **Class imbalance correction** ensures that presences aren't overshadowed by pseudo-absences, while multicollinearity checks ensure the predictors are independent and interpretable.\n",
    "2. **Multicollinearity** can cause instability in the model coefficients, leading to unreliable predictions, even after addressing class imbalances.\n",
    "3. **Redundant predictors** can reduce model generalisability, which is critical for your study's aim of reliable species distribution predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f05deb4-2d55-4358-88e2-ad25082baebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Feature Pairs:\n",
      " C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Building_Density_Reversed.tif                 C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Building_Density_Reversed.tif                   1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/DistWater_Reversed.tif                        C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/DistWater_Reversed.tif                          1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_StDev.tif                                         C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_StDev.tif                                           1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_median.tif                                        C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_median.tif                                          1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Grass_Stand.tif                                        C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Grass_Stand.tif                                          1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Wood_Resample_Reversed.tif                    C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Wood_Resample_Reversed.tif                      1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif                          C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif                            1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Slope_Proj_Reversed.tif                       C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Slope_Proj_Reversed.tif                         1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Runoff_Coefficient_Standardised_Reversed.tif  C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Runoff_Coefficient_Standardised_Reversed.tif    1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/RGS_Reversed.tif                              C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/RGS_Reversed.tif                                1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif                        C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif                          1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/SoilMoisture_32bit_Reversed.tif               C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/SoilMoisture_32bit_Reversed.tif                 1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/VegHeight.tif                                          C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/VegHeight.tif                                            1.00000\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif                          C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif                          0.89834\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif                        C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif                            0.89834\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute correlation matrix\n",
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "# Identify highly correlated features\n",
    "threshold = 0.75  # Define a threshold for high correlation\n",
    "high_corr_pairs = correlation_matrix.abs().unstack().sort_values(ascending=False)\n",
    "high_corr_pairs = high_corr_pairs[high_corr_pairs >= threshold]\n",
    "print(\"Highly Correlated Feature Pairs:\\n\", high_corr_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc72cf4-1d25-480b-8328-60f2f8d14f5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263dd6ea-7039-4f37-87e6-10bcd8712066",
   "metadata": {},
   "source": [
    "### **Key Observations**\n",
    "### 1. Perfect Correlation (Correlation = 1):\n",
    "- Predictors like `Building_Density_Reversed.tif`, `DistWater_Reversed.tif`, `VegHeight.tif`, etc., are perfectly correlated with themselves.\n",
    "- This is expected because a feature is always perfectly correlated with itself. These rows can be ignored.\n",
    "\n",
    "### 2. High Correlation Between Different Predictors:\n",
    "- Example: `Traffic_Reversed.tif` and `NOx_Stand_Reversed.tif` have a correlation of 0.889, suggesting they are highly redundant.\n",
    "- High correlations between different predictors indicate potential multicollinearity, which can destabilise the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "194ec59a-51d9-47da-8a56-b223fad73e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Predictor Pairs (Excluding Self-Correlation):\n",
      " C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif    C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif    0.89834\n",
      "C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif  C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif      0.89834\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "high_corr_pairs = high_corr_pairs[high_corr_pairs.index.get_level_values(0) != high_corr_pairs.index.get_level_values(1)]\n",
    "print(\"Highly Correlated Predictor Pairs (Excluding Self-Correlation):\\n\", high_corr_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e366e3-7a6d-4d83-b7a3-62682a9ebeca",
   "metadata": {},
   "source": [
    "The refined results indicate a high correlation (**0.889**) between `Traffic_Reversed.tif` and `NOx_Stand_Reversed.tif`. This redundancy should be addressed to improve the logistic regression model and avoid multicollinearity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e395ecb-66ed-43b0-a017-3e2267e851b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif' has been removed from the dataset.\n",
      "Retained Predictor: 'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif'\n",
      "\n",
      "Updated Predictors in X_train:\n",
      "Index(['C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Building_Density_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/DistWater_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/RGS_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Runoff_Coefficient_Standardised_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Slope_Proj_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/SoilMoisture_32bit_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Wood_Resample_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Grass_Stand.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_median.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_StDev.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/VegHeight.tif'],\n",
      "      dtype='object')\n",
      "\n",
      "Updated Predictors in X_test:\n",
      "Index(['C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Building_Density_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/DistWater_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/RGS_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Runoff_Coefficient_Standardised_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Slope_Proj_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/SoilMoisture_32bit_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Wood_Resample_Reversed.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Grass_Stand.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_median.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/NDVI_StDev.tif',\n",
      "       'C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/VegHeight.tif'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify the predictor to retain and the one to drop\n",
    "predictor_to_retain = \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/Traffic_Reversed.tif\"\n",
    "predictor_to_drop = \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif\"\n",
    "\n",
    "# Drop the less relevant predictor (NOx emissions) from the dataset\n",
    "X_train = X_train.drop(columns=[predictor_to_drop], errors='ignore')\n",
    "X_test = X_test.drop(columns=[predictor_to_drop], errors='ignore')\n",
    "\n",
    "print(f\"Predictor '{predictor_to_drop}' has been removed from the dataset.\")\n",
    "print(f\"Retained Predictor: '{predictor_to_retain}'\")\n",
    "\n",
    "# Verify the predictors in the dataset after removal\n",
    "print(\"\\nUpdated Predictors in X_train:\")\n",
    "print(X_train.columns)\n",
    "\n",
    "print(\"\\nUpdated Predictors in X_test:\")\n",
    "print(X_test.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bdecb3-c23d-447f-a34a-dcd01fdc6b42",
   "metadata": {},
   "source": [
    "### **Rationale for Predictor Selection**\n",
    "\n",
    "During the refinement of the Generalized Linear Model (GLM) for species distribution, high multicollinearity was identified between two traffic-related predictors: **traffic intensity** and **nitrogen oxide (NOx) emissions**. To enhance model stability and interpretability, it was necessary to select the most ecologically relevant predictor.\n",
    "\n",
    "#### Ecological Significance of Road-Related Mortality\n",
    "Amphibians are particularly vulnerable to road-induced mortality during migration and dispersal phases. The physical barriers imposed by roads and vehicular traffic result in significant population declines and habitat fragmentation. This phenomenon has been well-documented in ecological studies, emphasizing the critical impact of roads on amphibian survival (Glista et al., 2008). \n",
    "\n",
    "#### Addressing Multicollinearity in Predictors\n",
    "Multicollinearity between predictors can lead to unstable coefficient estimates, inflated standard errors, and diminished predictive accuracy in regression models. Retaining highly correlated predictors can introduce redundancy and reduce the reliability of model outputs. To ensure robust parameter estimation, it is essential to address multicollinearity (Graham, 2003).\n",
    "\n",
    "#### Selection of Traffic Intensity as the Key Predictor\n",
    "Based on ecological relevance and statistical considerations, **traffic intensity** was retained as the predictor representing road-related mortality. Traffic intensity directly measures a key source of mortality for amphibians, while NOx emissions, though correlated, do not provide as direct a connection to mortality rates. This decision aligns with ecological evidence and ensures the inclusion of a meaningful variable in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a468c9e-ec97-498b-b1e4-9ba15e00e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining GLM for Bufo bufo with adjusted predictors...\n",
      "Removed predictor: C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif\n",
      "  ROC-AUC for Bufo bufo: 0.829\n",
      "  Confusion Matrix:\n",
      "[[856 330]\n",
      " [ 30 111]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      1186\n",
      "           1       0.25      0.79      0.38       141\n",
      "\n",
      "    accuracy                           0.73      1327\n",
      "   macro avg       0.61      0.75      0.60      1327\n",
      "weighted avg       0.89      0.73      0.78      1327\n",
      "\n",
      "  Adjusted model saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Bufo bufo_GLM_Model_Adjusted.pkl\n",
      "  Adjusted metrics saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Bufo bufo_GLM_Metrics_Adjusted.txt\n",
      "Retraining GLM for Rana temporaria with adjusted predictors...\n",
      "Removed predictor: C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif\n",
      "  ROC-AUC for Rana temporaria: 0.819\n",
      "  Confusion Matrix:\n",
      "[[1998  490]\n",
      " [  73  172]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88      2488\n",
      "           1       0.26      0.70      0.38       245\n",
      "\n",
      "    accuracy                           0.79      2733\n",
      "   macro avg       0.61      0.75      0.63      2733\n",
      "weighted avg       0.90      0.79      0.83      2733\n",
      "\n",
      "  Adjusted model saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Rana temporaria_GLM_Model_Adjusted.pkl\n",
      "  Adjusted metrics saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Rana temporaria_GLM_Metrics_Adjusted.txt\n",
      "Retraining GLM for Lissotriton helveticus with adjusted predictors...\n",
      "Removed predictor: C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif\n",
      "  ROC-AUC for Lissotriton helveticus: 0.810\n",
      "  Confusion Matrix:\n",
      "[[497 166]\n",
      " [ 18  53]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.84       663\n",
      "           1       0.24      0.75      0.37        71\n",
      "\n",
      "    accuracy                           0.75       734\n",
      "   macro avg       0.60      0.75      0.60       734\n",
      "weighted avg       0.90      0.75      0.80       734\n",
      "\n",
      "  Adjusted model saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Lissotriton helveticus_GLM_Model_Adjusted.pkl\n",
      "  Adjusted metrics saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM/Lissotriton helveticus_GLM_Metrics_Adjusted.txt\n",
      "GLM retraining with adjusted predictors complete!\n"
     ]
    }
   ],
   "source": [
    "# Directory to save results\n",
    "output_dir = \"C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each species for GLM training\n",
    "for species in loaded_train_data.keys():\n",
    "    print(f\"Retraining GLM for {species} with adjusted predictors...\")\n",
    "    \n",
    "    # Get the GLM dataset for the species\n",
    "    data = loaded_train_data[species][\"GLM\"]\n",
    "    X = data.drop(columns=[\"label\"])  # Predictors\n",
    "    y = data[\"label\"]  # Response variable (presence/absence)\n",
    "    \n",
    "    # Remove the multicollinear predictor (NOx_Stand_Reversed.tif) from predictors\n",
    "    predictor_to_remove = \"C:/GIS_Course/MScThesis-MaviSantarelli/data/Predictors/Input/Reversed/NOx_Stand_Reversed.tif\"\n",
    "    if predictor_to_remove in X.columns:\n",
    "        X = X.drop(columns=[predictor_to_remove])\n",
    "        print(f\"Removed predictor: {predictor_to_remove}\")\n",
    "\n",
    "    # Split the data into training (70%) and testing (30%) subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train the GLM with class_weight='balanced'\n",
    "    glm = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "    glm.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = glm.predict(X_test)\n",
    "    y_pred_prob = glm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"  ROC-AUC for {species}: {roc_auc:.3f}\")\n",
    "    print(f\"  Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"  Classification Report:\\n{class_report}\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for {species} (GLM with Adjusted Predictors)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{output_dir}/{species}_GLM_ROC_Curve_Adjusted.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{output_dir}/{species}_GLM_Model_Adjusted.pkl\"\n",
    "    joblib.dump(glm, model_path)\n",
    "    print(f\"  Adjusted model saved for {species} at {model_path}\")\n",
    "\n",
    "    # Save evaluation metrics\n",
    "    metrics_path = f\"{output_dir}/{species}_GLM_Metrics_Adjusted.txt\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(f\"ROC-AUC: {roc_auc:.3f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{class_report}\\n\")\n",
    "    print(f\"  Adjusted metrics saved for {species} at {metrics_path}\")\n",
    "\n",
    "print(\"GLM retraining with adjusted predictors complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa964c-16e5-4e7b-a34f-b9003b9f3664",
   "metadata": {},
   "source": [
    "### **Interpretation of Results**\r\n",
    "\r\n",
    "#### 1. **Performance Consistency**:\r\n",
    "- The removal of the multicollinear predictor (`NOx_Stand_Reversed.tif`) had **minimal to no impact** on **ROC-AUC** and other performance metrics. This suggests that the predictor did not provide unique or critical information for improving predictions, confirming its redundancy due to multicollinearity with `Traffic_Reversed.tif`.\r\n",
    "\r\n",
    "#### 2. **High False Positives**:\r\n",
    "- For all species, **false positives** (predicting presence where it is not) remain relatively high. This could be a result of noise in the **pseudo-absence data** or limited predictive power of the GLM to distinguish presence and pseudo-absence.\r\n",
    "\r\n",
    "#### 3. **Improvements in Recall**:\r\n",
    "- **Recall** (sensitivity) for the presence class (Class 1) **remains high** across species, which is crucial for **conservation-focused studies** where capturing presence is more important than absolute accuracy. The high recall indicates a successful adjustment, improving the model’s sensitivity to the minority class (presences).\r\n",
    "\r\n",
    "#### 4. **Challenges with Precision**:\r\n",
    "- **Precision** (proportion of correctly identified presences out of total predicted presences) remains **low**, indicating that many of the predicted presences are **false positives**.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9424b5-608f-4669-9b5e-8495d36b7f7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2224d-14ef-4e3f-aad5-f029584d418c",
   "metadata": {},
   "source": [
    "### Step 3: Adding Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c448757-151e-4f2c-a714-4032042f9845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GLM with regularisation for Bufo bufo...\n",
      "  Ridge model saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Bufo bufo_GLM_Ridge_Model.pkl\n",
      "  Ridge metrics saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Bufo bufo_GLM_Ridge_Metrics.txt\n",
      "  Lasso model saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Bufo bufo_GLM_Lasso_Model.pkl\n",
      "  Lasso metrics saved for Bufo bufo at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Bufo bufo_GLM_Lasso_Metrics.txt\n",
      "  Ridge ROC-AUC for Bufo bufo: 0.831\n",
      "  Lasso ROC-AUC for Bufo bufo: 0.830\n",
      "Training GLM with regularisation for Rana temporaria...\n",
      "  Ridge model saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Rana temporaria_GLM_Ridge_Model.pkl\n",
      "  Ridge metrics saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Rana temporaria_GLM_Ridge_Metrics.txt\n",
      "  Lasso model saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Rana temporaria_GLM_Lasso_Model.pkl\n",
      "  Lasso metrics saved for Rana temporaria at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Rana temporaria_GLM_Lasso_Metrics.txt\n",
      "  Ridge ROC-AUC for Rana temporaria: 0.821\n",
      "  Lasso ROC-AUC for Rana temporaria: 0.821\n",
      "Training GLM with regularisation for Lissotriton helveticus...\n",
      "  Ridge model saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Lissotriton helveticus_GLM_Ridge_Model.pkl\n",
      "  Ridge metrics saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Lissotriton helveticus_GLM_Ridge_Metrics.txt\n",
      "  Lasso model saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Lissotriton helveticus_GLM_Lasso_Model.pkl\n",
      "  Lasso metrics saved for Lissotriton helveticus at C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised/Lissotriton helveticus_GLM_Lasso_Metrics.txt\n",
      "  Ridge ROC-AUC for Lissotriton helveticus: 0.809\n",
      "  Lasso ROC-AUC for Lissotriton helveticus: 0.812\n",
      "GLM training with regularisation complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Directory to save results\n",
    "output_dir = \"C:/GIS_Course/MScThesis-MaviSantarelli/results/GLM_Regularised\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each species for Ridge and Lasso regularisation\n",
    "for species, models in loaded_train_data.items():  # Use loaded_train_data instead of loaded_data\n",
    "    print(f\"Training GLM with regularisation for {species}...\")\n",
    "    \n",
    "    # Get the GLM training dataset for the species\n",
    "    data = models[\"GLM\"]\n",
    "    X = data.drop(columns=[\"label\"])  # Predictors\n",
    "    y = data[\"label\"]  # Response variable (presence/absence)\n",
    "\n",
    "    # Split the data into training (70%) and testing (30%) subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Define Ridge and Lasso models with cross-validation\n",
    "    ridge_model = LogisticRegressionCV(cv=5, penalty='l2', solver='liblinear', max_iter=1000, scoring='roc_auc', class_weight='balanced', random_state=42)\n",
    "    lasso_model = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', max_iter=1000, scoring='roc_auc', class_weight='balanced', random_state=42)\n",
    "\n",
    "    # Train Ridge model\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    ridge_y_pred = ridge_model.predict(X_test)\n",
    "    ridge_y_pred_prob = ridge_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Train Lasso model\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    lasso_y_pred = lasso_model.predict(X_test)\n",
    "    lasso_y_pred_prob = lasso_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluate Ridge model\n",
    "    ridge_roc_auc = roc_auc_score(y_test, ridge_y_pred_prob)\n",
    "    ridge_conf_matrix = confusion_matrix(y_test, ridge_y_pred)\n",
    "    ridge_class_report = classification_report(y_test, ridge_y_pred)\n",
    "\n",
    "    # Evaluate Lasso model\n",
    "    lasso_roc_auc = roc_auc_score(y_test, lasso_y_pred_prob)\n",
    "    lasso_conf_matrix = confusion_matrix(y_test, lasso_y_pred)\n",
    "    lasso_class_report = classification_report(y_test, lasso_y_pred)\n",
    "\n",
    "    # Save Ridge results\n",
    "    ridge_model_path = f\"{output_dir}/{species}_GLM_Ridge_Model.pkl\"\n",
    "    joblib.dump(ridge_model, ridge_model_path)\n",
    "    print(f\"  Ridge model saved for {species} at {ridge_model_path}\")\n",
    "    \n",
    "    ridge_metrics_path = f\"{output_dir}/{species}_GLM_Ridge_Metrics.txt\"\n",
    "    with open(ridge_metrics_path, \"w\") as f:\n",
    "        f.write(f\"ROC-AUC: {ridge_roc_auc:.3f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{ridge_conf_matrix}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{ridge_class_report}\\n\")\n",
    "    print(f\"  Ridge metrics saved for {species} at {ridge_metrics_path}\")\n",
    "\n",
    "    # Save Lasso results\n",
    "    lasso_model_path = f\"{output_dir}/{species}_GLM_Lasso_Model.pkl\"\n",
    "    joblib.dump(lasso_model, lasso_model_path)\n",
    "    print(f\"  Lasso model saved for {species} at {lasso_model_path}\")\n",
    "    \n",
    "    lasso_metrics_path = f\"{output_dir}/{species}_GLM_Lasso_Metrics.txt\"\n",
    "    with open(lasso_metrics_path, \"w\") as f:\n",
    "        f.write(f\"ROC-AUC: {lasso_roc_auc:.3f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{lasso_conf_matrix}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{lasso_class_report}\\n\")\n",
    "    print(f\"  Lasso metrics saved for {species} at {lasso_metrics_path}\")\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"  Ridge ROC-AUC for {species}: {ridge_roc_auc:.3f}\")\n",
    "    print(f\"  Lasso ROC-AUC for {species}: {lasso_roc_auc:.3f}\")\n",
    "\n",
    "print(\"GLM training with regularisation complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bc115-bc82-434a-a595-70c51dfb7682",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdee7f4-9eb3-411c-942e-15f182a6884c",
   "metadata": {},
   "source": [
    "### **Analysis of Results**\r\n",
    "\r\n",
    "#### 1. **Impact of Regularisation**:\r\n",
    "- Regularisation stabilises the models by reducing overfitting and multicollinearity.\r\n",
    "- **Ridge** consistently performs slightly better than **Lasso** for all species, although the difference is marginal. \r\n",
    "    - **Bufo bufo**: Ridge performs better than Lasso, with a slight improvement in ROC-AUC (0.831 vs 0.830).\r\n",
    "    - **Rana temporaria**: Both Ridge and Lasso have identical performance, with a ROC-AUC of 0.821.\r\n",
    "    - **Lissotriton helveticus**: Lasso performs slightly better than Ridge, with a ROC-AUC of 0.812 compared to 0.809.\r\n",
    "\r\n",
    "#### 2. **Performance Consistency**:\r\n",
    "- The regularisation techniques do not drastically improve the **ROC-AUC** scores compared to the unregularised GLM. However, they help **ensure better model generalisation**, particularly when dealing with overfitting and multicollinearity. The performance improvement is more subtle but valuable for improving model stability.\r\n",
    "\r\n",
    "#### 3. **Species-Specific Observations**:\r\n",
    "- ***Bufo bufo***: **Ridge** slightly outperforms **Lasso**, with the ROC-AUC of 0.831 compared to 0.830, suggesting that **Ridge** provides a more stable and consistent performance for this species.\r\n",
    "- ***Rana temporaria***: The model is already robust, as evidenced by the unchanged performance (both Ridge and Lasso achieve a ROC-AUC of 0.821). Regularisation does not significantly affect the model’s effectiveness for this species.\r\n",
    "- ***Lissotriton helveticus***: **Lasso** marginally outperforms **Ridge** (0.812 vs 0.809), suggesting that **Lasso’s** feature selection ability may be beneficial for this species, even though it slightly underperforms i feature selection and stability.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d5d14-5078-4f61-9248-7c4df97f5776",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22e32d-aedd-4b43-b5ba-f57f54530a91",
   "metadata": {},
   "source": [
    "### Step 4: Hyperparameter Tuning\n",
    "\n",
    "\r\n",
    "In this step, we use **Grid Search** to tune the regularization strength (`C`) for the **Ridge (L2)** and **Lasso (L1)** regularized logistic regression models. Regularization helps prevent overfitting by adding a penalty term to the model, controlling the complexity of the learned coefficients.\r\n",
    "\r\n",
    "The parameter `C` (or `Cs` in **LogisticRegressionCV**) controls the regularization strength:\r\n",
    "- **Lower values of `C`** indicate **stronger regularization** (penalty), resulting in a simpler model with fewer non-zero coefficients.\r\n",
    "- **Higher values of `C`** indicate **weaker regularization**, allowing the model to fit the training data more closely.\r\n",
    "\r\n",
    "By using **GridSearchCV**, we explore a range of possible values for `C` (from `0.01` to `100`) to find the optimal balance between model complexity and performance. The **ROC-AUC** score is used as the evaluation metric during cross-validation to determine the best regularization strength.\r\n",
    "\r\n",
    "This tuning step ensures that the model is neither overfitting nor underfitting, improving its generalizatioability.\r\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21192c9d-f96e-4195-9791-d2ee75ca0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Define parameter grid for regularisation strength\n",
    "param_grid = {\n",
    "    'Cs': [[0.01, 0.1, 1, 10, 100]]  # Range of C values to explore (as an array)\n",
    "}\n",
    "\n",
    "# Grid search for Ridge\n",
    "ridge_grid_search = GridSearchCV(LogisticRegressionCV(cv=5, penalty='l2', solver='liblinear', max_iter=1000, scoring='roc_auc', class_weight='balanced', random_state=42), param_grid, cv=5)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Ridge Model:\", ridge_grid_search.best_params_)\n",
    "\n",
    "# Grid search for Lasso\n",
    "lasso_grid_search = GridSearchCV(LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', max_iter=1000, scoring='roc_auc', class_weight='balanced', random_state=42), param_grid, cv=5)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Lasso Model:\", lasso_grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c089b37-4b46-461f-9865-b1910cbad400",
   "metadata": {},
   "source": [
    "## References\n",
    "- Glista, D. J., DeVault, T. L., & DeWoody, J. A. (2008). A review of mitigation measures for reducing wildlife mortality on roadways. *Herpetological Conservation and Biology, 3*(1), 16–28. Retrieved from [https://www.herpconbio.org/Volume_3/Issue_1/Glista_etal_2008.pdf](https://www.herpconbio.org/Volume_3/Issue_1/Glista_etal_2008.pdf)\n",
    "\n",
    "- Graham, M. H. (2003). Confronting multicollinearity in ecological multiple regression. *Ecology, 84*(11), 2809–2815. Retrieved from [https://webhome.auburn.edu/~tds0009/Articles/Graham%202003.pdf](https://webhome.auburn.edu/~tds0009/Articles/Graham%202003.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbab85-e348-4400-b2a7-4b0960ed6175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MscThesis)",
   "language": "python",
   "name": "mscthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
