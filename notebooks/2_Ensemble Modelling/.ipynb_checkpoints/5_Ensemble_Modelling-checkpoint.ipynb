{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84671b3-627a-4537-a768-d2e886c7c0ae",
   "metadata": {},
   "source": [
    "# Ensemble Modelling\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Ensemble Methodology](#2.-Ensemble-Methodology)\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Ensemble modelling is a machine learning technique that combines multiple individual models to improve predictive performance. By aggregating the strengths of diverse models, ensembles often achieve better accuracy and robustness than any single model alone. \n",
    "\n",
    "In the context of species distribution modelling (SDM), ensemble approaches integrate predictions from various statistical techniques to enhance the reliability of forecasts. This method accounts for uncertainties inherent in individual models, leading to more robust predictions.\n",
    "\n",
    "### **Common Ensemble Methods**\n",
    "\n",
    "1. **Bagging (Bootstrap Aggregating)**: This technique involves training multiple models on different subsets of the data, created through random sampling with replacement. The final prediction is typically an average (for regression) or majority vote (for classification) of the individual models' outputs. \n",
    "\n",
    "2. **Boosting**: Boosting sequentially trains models, each focusing on correcting the errors of its predecessor. Models are weighted based on their performance, and the ensemble combines them to produce a strong predictor. \n",
    "\n",
    "3. **Stacking**: In stacking, multiple models are trained to predict the same outcome. Their predictions are then used as inputs for a higher-level model, which learns to combine them optimally.\n",
    "\n",
    "## 2. Ensemble Methodology\n",
    "\n",
    "### **2.1 Selection of Models for Ensemble**\n",
    "Based on the previous model evaluation and comparison, Random Forest (RF) and XGBoost consistently outperformed other models, demonstrating the highest AUC-ROC, precision, recall, and F1-score across all species. MaxEnt showed moderate performance, particularly in recall, but had limitations in precision, suggesting a tendency for overprediction. GLM and GAM performed the worst overall, indicating they may not fully capture the complexity of amphibian distributions.\n",
    "\n",
    "Thus, this study will prioritise RF and XGBoost as the core models in the ensemble and consider MaxEnt for added diversity while downweighting its influence. GLM and GAM may still contribute to the ensemble for additional variance but will not drive final predictions.\n",
    "\n",
    "### **2.2 Model Weighting and Aggregation Methods**\n",
    "To integrate multiple models, this study will explore different ensemble techniques:\n",
    "\n",
    "#### 1. Averaging Ensemble:\n",
    "- Compute the mean probability of presence across RF, XGBoost, and MaxEnt.\n",
    "- Weight models according to their precision and recall (e.g., RF and XGBoost given higher weight, MaxEnt downweighted).\n",
    "#### 2. Majority Voting Ensemble (for binary presence/absence predictions):\n",
    "- Classify a species as present if at least two out of three models predict presence.\n",
    "#### 3. Stacked Ensemble (if time allows):\n",
    "Train a meta-classifier (e.g., logistic regression) using predictions from individual models as inputs.\n",
    "\n",
    "### **2.3 Calibration and Performance Evaluation**\n",
    "To ensure the ensemble predictions are robust, the following evaluation metrics will be recalculated:\n",
    "\n",
    "- AUC-ROC and Precision-Recall curves\n",
    "- Sensitivity-specificity trade-offs\n",
    "- Confusion matrix analysis\n",
    "- Uncertainty quantification (standard deviation in predictions)\n",
    "\n",
    "The ensemble's performance will be compared to individual models to determine whether it achieves higher predictive accuracy and reliability.\n",
    "\n",
    "### **2.4 Spatial Mapping of Ensemble Predictions**\n",
    "Once ensemble predictions are finalised, they will be spatially visualised using GIS tools to assess habitat suitability for target amphibian species. Uncertainty maps will also be generated to highlight regions with high model disagreement.\n",
    "\n",
    "### **2.5 Methodology Rationale**\n",
    "This study aims to leverage the advantages of ensemble modelling to provide more accurate, reliable, and ecologically meaningful habitat suitability predictions. The rationale for this approach is:\n",
    "1. Tree-based models (RF and XGBoost) demonstrate strong performance and capture complex species-environment relationships.\n",
    "2. MaxEnt contributes additional ecological insightsand has been widely used in SDMs, but its predictions will be weighted lower to account for overprediction tendencies.\n",
    "3. Averaging and majority voting improve robustness, ensuring predictions are not overly reliant on any single model.\n",
    "4. Uncertainty quantification will guide conservation decision-making, particularly for identifying regions where predictions are less certain.\n",
    "\n",
    "By following this approach, the ensemble model will integrate the strengths of individual models, enhance predictive reliability, and contribute valuable insights for amphibian conservation and Blue-Green Infrastructure planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7188149-0c65-40b5-bc30-339405a97144",
   "metadata": {},
   "source": [
    "## 3. Ensemble Modelling\n",
    "### 3.1 Load Model Predictions and Prepare for Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d12974-c5b0-43cf-95cb-3bd2eb8a87ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Processing ensemble predictions for Bufo bufo...\n",
      "âœ… Merged predictions saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\\Bufo bufo_Ensemble_Predictions.csv\n",
      "ðŸ” Processing ensemble predictions for Rana temporaria...\n",
      "âœ… Merged predictions saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\\Rana temporaria_Ensemble_Predictions.csv\n",
      "ðŸ” Processing ensemble predictions for Lissotriton helveticus...\n",
      "âœ… Merged predictions saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\\Lissotriton helveticus_Ensemble_Predictions.csv\n",
      "\n",
      "ðŸš€ Ensemble prediction files ready for next steps!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define base directory\n",
    "base_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\"\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Define selected models for ensemble\n",
    "selected_models = [\"RF\", \"XGBoost\", \"MaxEnt\"]\n",
    "\n",
    "# Define paths for each model\n",
    "model_dirs = {\n",
    "    \"RF\": os.path.join(base_dir, \"RandomForest\"),\n",
    "    \"XGBoost\": os.path.join(base_dir, \"XGBoost\"),\n",
    "    \"MaxEnt\": os.path.join(base_dir, \"Maxent\")\n",
    "}\n",
    "\n",
    "# Define file patterns for each model\n",
    "file_patterns = {\n",
    "    \"RF\": os.path.join(\"{species}\", \"Test_Predictions.csv\"),\n",
    "    \"XGBoost\": os.path.join(\"{species}\", \"Aggregated_Test_Predictions.csv\"),\n",
    "    \"MaxEnt\": \"Maxent_{species}_TestPredictions.csv\"\n",
    "}\n",
    "\n",
    "# Define output directory for merged predictions\n",
    "ensemble_output_dir = os.path.join(base_dir, \"Ensemble_Predictions\")\n",
    "os.makedirs(ensemble_output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each species\n",
    "for species in species_list:\n",
    "    print(f\"ðŸ” Processing ensemble predictions for {species}...\")\n",
    "\n",
    "    merged_df = None  # Initialize dataframe for storing merged predictions\n",
    "\n",
    "    for model in selected_models:\n",
    "        formatted_species = species.replace(\" \", \"_\")  # Adjust for file naming\n",
    "        file_path = os.path.join(model_dirs[model], file_patterns[model].format(species=formatted_species))\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âš ï¸ Missing prediction file for {species} - {model}: {file_path}\")\n",
    "            continue  # Skip this model if the file is missing\n",
    "\n",
    "        # Load model predictions in chunks (if necessary)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, dtype={\"True_Label\": \"int8\", \"Predicted_Probability\": \"float32\"})\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error loading {species} - {model}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Rename columns\n",
    "        df = df.rename(columns={\"True_Label\": \"True_Label\", \"Predicted_Probability\": f\"{model}_Probability\"})\n",
    "\n",
    "        # Reduce memory usage\n",
    "        df[f\"{model}_Probability\"] = df[f\"{model}_Probability\"].astype(np.float32)\n",
    "\n",
    "        # Merge into a single dataframe\n",
    "        if merged_df is None:\n",
    "            merged_df = df.copy()\n",
    "        else:\n",
    "            merged_df = pd.concat([merged_df, df[f\"{model}_Probability\"]], axis=1)\n",
    "\n",
    "        del df  # Free up memory\n",
    "\n",
    "    # Save the merged predictions in chunks\n",
    "    if merged_df is not None and not merged_df.empty:\n",
    "        output_file = os.path.join(ensemble_output_dir, f\"{species}_Ensemble_Predictions.csv\")\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"âœ… Merged predictions saved: {output_file}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No valid predictions available for {species}.\")\n",
    "\n",
    "    del merged_df  # Free memory after each species\n",
    "\n",
    "print(\"\\nðŸš€ Ensemble prediction files ready for next steps!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74566b61-58ef-4ac4-a20e-11d840e233c2",
   "metadata": {},
   "source": [
    "### 3.2 Weighted Ensemble Averaging\n",
    "\n",
    "**Why Use Averaging?**\n",
    "- This approach reduces individual model biases and leverages the strengths of multiple models.\n",
    "- Averaging probabilities smooths extreme values, leading to better generalisation.\n",
    "- It is less prone to overfitting compared to single models.\n",
    "\n",
    "The code below assigns weights based on **multiple performance metrics** (AUC-ROC, Precision, Recall, and F1-score), normalises them, and applies a weighted averaging scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24e1c6d-b4a1-4756-8399-bf0a1e106b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Computing weighted ensemble predictions for Bufo bufo...\n",
      "âœ… Saved weighted predictions for Bufo bufo at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Bufo bufo_Weighted_Ensemble_Predictions.csv\n",
      "ðŸ” Computing weighted ensemble predictions for Rana temporaria...\n",
      "âœ… Saved weighted predictions for Rana temporaria at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Rana temporaria_Weighted_Ensemble_Predictions.csv\n",
      "ðŸ” Computing weighted ensemble predictions for Lissotriton helveticus...\n",
      "âœ… Saved weighted predictions for Lissotriton helveticus at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Lissotriton helveticus_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "ðŸš€ Weighted ensemble averaging complete! Ready for threshold selection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output directories\n",
    "ensemble_input_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Ensemble_Predictions\"\n",
    "ensemble_output_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\"\n",
    "os.makedirs(ensemble_output_dir, exist_ok=True)\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Define performance metrics for weighting (these values should be updated with your actual model metrics)\n",
    "performance_metrics = {\n",
    "    \"Bufo bufo\": {\n",
    "        \"RF\": {\"AUC-ROC\": 0.910, \"Precision\": 0.994, \"Recall\": 0.816, \"F1\": 0.896},\n",
    "        \"XGBoost\": {\"AUC-ROC\": 0.875, \"Precision\": 0.809, \"Recall\": 0.801, \"F1\": 0.805},\n",
    "        \"MaxEnt\": {\"AUC-ROC\": 0.867, \"Precision\": 0.419, \"Recall\": 0.720, \"F1\": 0.530},\n",
    "    },\n",
    "    \"Rana temporaria\": {\n",
    "        \"RF\": {\"AUC-ROC\": 0.949, \"Precision\": 1.000, \"Recall\": 0.863, \"F1\": 0.927},\n",
    "        \"XGBoost\": {\"AUC-ROC\": 0.909, \"Precision\": 0.837, \"Recall\": 0.855, \"F1\": 0.846},\n",
    "        \"MaxEnt\": {\"AUC-ROC\": 0.869, \"Precision\": 0.363, \"Recall\": 0.656, \"F1\": 0.467},\n",
    "    },\n",
    "    \"Lissotriton helveticus\": {\n",
    "        \"RF\": {\"AUC-ROC\": 0.915, \"Precision\": 0.989, \"Recall\": 0.777, \"F1\": 0.870},\n",
    "        \"XGBoost\": {\"AUC-ROC\": 0.834, \"Precision\": 0.803, \"Recall\": 0.757, \"F1\": 0.779},\n",
    "        \"MaxEnt\": {\"AUC-ROC\": 0.837, \"Precision\": 0.336, \"Recall\": 0.636, \"F1\": 0.440},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Normalise weights across species\n",
    "for species in species_list:\n",
    "    model_weights = {}\n",
    "    for model in performance_metrics[species].keys():\n",
    "        # Compute an average of all normalised scores for balanced weighting\n",
    "        metrics = performance_metrics[species][model]\n",
    "        model_weights[model] = np.mean([metrics[\"AUC-ROC\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1\"]])\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    total_weight = sum(model_weights.values())\n",
    "    for model in model_weights.keys():\n",
    "        model_weights[model] /= total_weight  # Scale to sum up to 1\n",
    "\n",
    "    performance_metrics[species][\"Weights\"] = model_weights  # Store normalised weights\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    print(f\"ðŸ” Computing weighted ensemble predictions for {species}...\")\n",
    "\n",
    "    # Load ensemble predictions file\n",
    "    file_path = os.path.join(ensemble_input_dir, f\"{species}_Ensemble_Predictions.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âš ï¸ Missing ensemble file for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify probability columns\n",
    "    probability_columns = [col for col in df.columns if col.endswith(\"_Probability\")]\n",
    "\n",
    "    if len(probability_columns) == 0:\n",
    "        print(f\"âš ï¸ No probability columns found for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Compute weighted ensemble probability\n",
    "    weighted_predictions = np.zeros(len(df))\n",
    "\n",
    "    for model in probability_columns:\n",
    "        model_name = model.replace(\"_Probability\", \"\")  # Extract model name\n",
    "        if model_name in performance_metrics[species][\"Weights\"]:\n",
    "            weighted_predictions += df[model] * performance_metrics[species][\"Weights\"][model_name]\n",
    "        else:\n",
    "            print(f\"âš ï¸ Missing weight for {model_name} in {species}. Skipping.\")\n",
    "\n",
    "    df[\"Weighted_Ensemble\"] = weighted_predictions\n",
    "\n",
    "    # Save the weighted ensemble predictions\n",
    "    output_file = os.path.join(ensemble_output_dir, f\"{species}_Weighted_Ensemble_Predictions.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"âœ… Saved weighted predictions for {species} at {output_file}\")\n",
    "\n",
    "print(\"\\nðŸš€ Weighted ensemble averaging complete! Ready for threshold selection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee003947-2763-4ecf-96e6-2f16f2724cea",
   "metadata": {},
   "source": [
    "### 3.3 Selecting the Optimal Threshold for Presence-Absence Classification\n",
    "\n",
    "Now that the weighted ensemble predictions have been generated, the next step is threshold selection, which converts probability predictions into binary presence/absence values. We have multiple options to determine the best threshold:\n",
    "\n",
    "#### 1. Maximising the F1-score:\n",
    "* The best balance between precision and recall.\n",
    "* Ideal if you want to avoid too many false positives or false negatives.\n",
    "\n",
    "#### 2. Maximising the Youden Index (J-Statistic):\n",
    "* The threshold that maximises (Sensitivity + Specificity - 1).\n",
    "* Ensures both presence and absence are well-classified.\n",
    "\n",
    "#### 3. Fixed Threshold (e.g., 0.5):\n",
    "* Simple but not species-specific.\n",
    "* May not be optimal given imbalanced data.\n",
    "\n",
    "All three methods will be implemented and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1762fd1-6db3-42fc-9da7-930de024650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Bufo bufo - Missing Values:\n",
      "True_Label              3870\n",
      "RF_Probability          3870\n",
      "XGBoost_Probability        0\n",
      "MaxEnt_Probability      2405\n",
      "Weighted_Probability    3870\n",
      "dtype: int64\n",
      "\n",
      "âœ… Cleaned and saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Bufo bufo_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "ðŸ” Rana temporaria - Missing Values:\n",
      "True_Label              5994\n",
      "RF_Probability          5994\n",
      "XGBoost_Probability        0\n",
      "MaxEnt_Probability      2756\n",
      "Weighted_Probability    5994\n",
      "dtype: int64\n",
      "\n",
      "âœ… Cleaned and saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Rana temporaria_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "ðŸ” Lissotriton helveticus - Missing Values:\n",
      "True_Label              1827\n",
      "RF_Probability          1827\n",
      "XGBoost_Probability        0\n",
      "MaxEnt_Probability       981\n",
      "Weighted_Probability    1827\n",
      "dtype: int64\n",
      "\n",
      "âœ… Cleaned and saved: C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\\Lissotriton helveticus_Weighted_Ensemble_Predictions.csv\n",
      "\n",
      "ðŸš€ Data cleaning complete! Now re-run threshold selection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory for weighted ensemble predictions\n",
    "weighted_ensemble_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\"\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    file_path = os.path.join(weighted_ensemble_dir, f\"{species}_Weighted_Ensemble_Predictions.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âš ï¸ Missing weighted ensemble file for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Check for NaN values\n",
    "    nan_counts = df.isnull().sum()\n",
    "    print(f\"\\nðŸ” {species} - Missing Values:\\n{nan_counts}\\n\")\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Ensure True_Label is binary (0 or 1) and integer\n",
    "    df[\"True_Label\"] = df[\"True_Label\"].astype(int)\n",
    "\n",
    "    # Ensure Weighted_Probability is numeric\n",
    "    df[\"Weighted_Probability\"] = df[\"Weighted_Probability\"].astype(float)\n",
    "\n",
    "    # Save cleaned dataset\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"âœ… Cleaned and saved: {file_path}\")\n",
    "\n",
    "print(\"\\nðŸš€ Data cleaning complete! Now re-run threshold selection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b52c299-6109-44e1-8e23-33d8212a871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Selecting threshold for Bufo bufo...\n",
      "âœ… Saved binary predictions for Bufo bufo at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Bufo bufo_Final_Binary_Predictions.csv\n",
      "ðŸ” Selecting threshold for Rana temporaria...\n",
      "âœ… Saved binary predictions for Rana temporaria at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Rana temporaria_Final_Binary_Predictions.csv\n",
      "ðŸ” Selecting threshold for Lissotriton helveticus...\n",
      "âœ… Saved binary predictions for Lissotriton helveticus at C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\\Lissotriton helveticus_Final_Binary_Predictions.csv\n",
      "\n",
      "ðŸš€ Threshold selection complete! Ready for final evaluation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n",
    "\n",
    "# Define input/output directories\n",
    "weighted_ensemble_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Weighted_Ensemble\"\n",
    "binary_output_dir = r\"C:\\GIS_Course\\MScThesis-MaviSantarelli\\results\\Models\\Final_Binary\"\n",
    "os.makedirs(binary_output_dir, exist_ok=True)\n",
    "\n",
    "# Define species list\n",
    "species_list = [\"Bufo bufo\", \"Rana temporaria\", \"Lissotriton helveticus\"]\n",
    "\n",
    "# Function to find the best threshold using F1-score and Youden Index\n",
    "def find_best_threshold(y_true, y_pred_prob):\n",
    "    # Compute F1-score optimal threshold\n",
    "    precisions, recalls, thresholds_pr = precision_recall_curve(y_true, y_pred_prob)\n",
    "    f1_scores = (2 * precisions * recalls) / (precisions + recalls + 1e-9)  # Avoid division by zero\n",
    "    best_f1_threshold = thresholds_pr[np.argmax(f1_scores)]\n",
    "\n",
    "    # Compute Youden's J Index optimal threshold\n",
    "    fpr, tpr, thresholds_roc = roc_curve(y_true, y_pred_prob)\n",
    "    youden_index = tpr - fpr\n",
    "    best_youden_threshold = thresholds_roc[np.argmax(youden_index)]\n",
    "\n",
    "    return best_f1_threshold, best_youden_threshold\n",
    "\n",
    "# Iterate through each species\n",
    "for species in species_list:\n",
    "    print(f\"ðŸ” Selecting threshold for {species}...\")\n",
    "\n",
    "    # Load weighted ensemble predictions\n",
    "    file_path = os.path.join(weighted_ensemble_dir, f\"{species}_Weighted_Ensemble_Predictions.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âš ï¸ Missing weighted ensemble file for {species}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"True_Label\" not in df.columns or \"Weighted_Probability\" not in df.columns:\n",
    "        print(f\"âš ï¸ Columns missing in {species} predictions. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    y_true = df[\"True_Label\"].values\n",
    "    y_pred_prob = df[\"Weighted_Probability\"].values\n",
    "\n",
    "    # Compute best thresholds\n",
    "    best_f1_threshold, best_youden_threshold = find_best_threshold(y_true, y_pred_prob)\n",
    "\n",
    "    # Apply thresholds to create binary presence/absence classifications\n",
    "    df[\"Binary_F1\"] = (df[\"Weighted_Probability\"] >= best_f1_threshold).astype(int)\n",
    "    df[\"Binary_Youden\"] = (df[\"Weighted_Probability\"] >= best_youden_threshold).astype(int)\n",
    "    df[\"Binary_0.5\"] = (df[\"Weighted_Probability\"] >= 0.5).astype(int)  # Fixed threshold\n",
    "\n",
    "    # Save binary classification results\n",
    "    output_file = os.path.join(binary_output_dir, f\"{species}_Final_Binary_Predictions.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"âœ… Saved binary predictions for {species} at {output_file}\")\n",
    "\n",
    "print(\"\\nðŸš€ Threshold selection complete! Ready for final evaluation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ed00c-2b22-41bf-bf2a-b5febb6500a7",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "Meller, L., Cabeza, M., Pironon, S., Barbet-Massin, M., Maiorano, L., Georges, D., & Thuiller, W. (2014). Ensemble distribution models in conservation prioritization: From consensus predictions to consensus reserve networks. *Diversity and Distributions*, 20(3), 309â€“321. https://doi.org/10.1111/ddi.12162\n",
    "\n",
    "Ramirez-Reyes, C., Nazeri, M., Street, G., Jones-Farrand, D. T., Vilella, F. J., & Evans, K. O. (2021). Embracing ensemble species distribution models to inform at-risk species status assessments. *Journal of Fish and Wildlife Management*, 12(1), 98â€“111. https://doi.org/10.3996/JFWM-20-072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c485ca-6fda-4bc7-a649-ef1bd37004a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
